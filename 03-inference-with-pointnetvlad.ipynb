{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaybie/.conda/envs/mr-environment/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srv/jaybie/archive/spatial-privacy-master/pointnetvlad_submaps/\n",
      "Trajectories Loaded.\n",
      "['raw_dataset', 'ransac_dataset']\n",
      "Training df for: raw_dataset\n",
      "Training df for: ransac_dataset\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import socket\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "#BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "#sys.path.append(BASE_DIR)\n",
    "from pointnetvlad_eval import *\n",
    "from sklearn.neighbors import NearestNeighbors, KDTree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_PATH = 'pointnetvlad_submaps/'\n",
    "\n",
    "RESULTS_FOLDER=\"testing_results/pointnetvlad/\"\n",
    "if not os.path.exists(RESULTS_FOLDER): os.mkdir(RESULTS_FOLDER)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-time partial release case: Spatial inference using pointnetvlad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pickle file yet: partial_results_updated_refs.pickle\n",
      "Trajectories Loaded.\n",
      "Doing pointnetvlad_submaps/3d_ransac_partial_radius_0.25_4096_unassisted_evaluation_query.pickle pointnetvlad_submaps/ransac_partial_radius_0.25_4096_unassisted\n",
      "WARNING:tensorflow:Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n",
      "WARNING:tensorflow:From /srv/jaybie/archive/spatial-privacy-master/loupe.py:168: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Tensor(\"query_triplets/Mul_1:0\", shape=(51, 256), dtype=float32, device=/device:GPU:0)\n",
      "INFO:tensorflow:Restoring parameters from model/model_3d_4m_jittered_4096.ckpt\n",
      "Model restored.\n",
      "(27912, 256)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-02044699a88d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Doing\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mQUERY_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquery_partial_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mave_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mave_intra_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQUERY_SETS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQUERY_DATABASE_NUMPY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     results_pickle.append([\n",
      "\u001b[0;32m/srv/jaybie/archive/spatial-privacy-master/pointnetvlad_eval.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(query_sets, query_db_np, output_file)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATABASE_VECTORS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATABASE_SETS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0mDATABASE_VECTORS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_latent_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATABASE_SETS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_sets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/jaybie/archive/spatial-privacy-master/pointnetvlad_eval.py\u001b[0m in \u001b[0;36mget_latent_vectors\u001b[0;34m(sess, ops, dict_to_process)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mq3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_NUM_QUERIES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNEGATIVES_PER_QUERY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNUM_POINTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'query'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mq1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'positives'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mq2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'negatives'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mq3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_training_pl'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mo1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'q_vec'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos_vecs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'neg_vecs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mo1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mr-environment/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mr-environment/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mr-environment/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mr-environment/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mr-environment/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mr-environment/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pickle_file = 'partial_results_updated_refs.pickle'\n",
    "\n",
    "try:\n",
    "    with open(RESULTS_FOLDER + pickle_file,'rb') as pickle_output:\n",
    "        results_pickle = pickle.load(pickle_output)\n",
    "except:\n",
    "    print(\"No pickle file yet:\",pickle_file)\n",
    "    results_pickle = []\n",
    "    \n",
    "for radius in np.arange(0.25,3.1,0.25):\n",
    "    \n",
    "    query_fol = 'ransac_partial_radius_'+str(radius)+\"_4096_unassisted\"#\n",
    "    \n",
    "    QUERY_FILE = 'pointnetvlad_submaps/3d_{}_evaluation_query.pickle'.format(query_fol)\n",
    "    \n",
    "    output_file = RESULTS_FOLDER +pickle_file+query_fol+'.txt'\n",
    "    \n",
    "    QUERY_SETS= get_sets_dict(QUERY_FILE)\n",
    "\n",
    "    query_partial_path = os.path.join(QUERY_PATH,query_fol)\n",
    "\n",
    "    df_test= pd.read_csv(os.path.join(query_partial_path,\"pointcloud_centroids_4m.csv\"),sep=',')\n",
    "    \n",
    "    QUERY_DATABASE_NUMPY = np.asarray(df_test)\n",
    "    \n",
    "    print(\"Doing\",QUERY_FILE,query_partial_path)\n",
    "    \n",
    "    ave_recall, ave_intra_dist = evaluate(QUERY_SETS, QUERY_DATABASE_NUMPY, output_file)\n",
    "    \n",
    "    results_pickle.append([\n",
    "            radius,\n",
    "            ave_recall,\n",
    "            ave_intra_dist\n",
    "        ])\n",
    "\n",
    "    with open(RESULTS_FOLDER + pickle_file,'wb') as pickle_output:\n",
    "        pickle.dump(results_pickle,pickle_output)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results: One-time release case with pointnetVLAD (vs NN-matcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = 'partial_results_updated_refs.pickle'\n",
    "\n",
    "try:\n",
    "    with open(RESULTS_FOLDER + pickle_file,'rb') as pickle_output:\n",
    "        results_pickle = pickle.load(pickle_output)\n",
    "except:\n",
    "    print(\"No results.\")\n",
    "    \n",
    "pointnetvlad = []\n",
    "\n",
    "for radius, recall, intra_dist in results_pickle:\n",
    "    pointnetvlad.append([\n",
    "        radius,\n",
    "        recall[0],\n",
    "        intra_dist[0]\n",
    "    ])\n",
    "    \n",
    "pointnetvlad = np.asarray(pointnetvlad)\n",
    "\n",
    "with open('testing_results/partial/results_partials_nn_matcher.pickle', 'rb') as f:\n",
    "    results_partials = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(12, 3))\n",
    "\n",
    "ax1 = fig.add_subplot(121) \n",
    "\n",
    "ax1.grid(alpha = 0.7)\n",
    "ax1.set_ylim(-0.025,1.025)\n",
    "ax1.set_xlim(0,3.0)\n",
    "ax1.set_ylabel(\"INTER-space Privacy, $\\Pi_1$\", fontsize = 14)\n",
    "ax1.set_xlabel(\"Partial Radius (m)\", fontsize = 14)\n",
    "\n",
    "markersize = 7\n",
    "linewidth = 1.5\n",
    "\n",
    "RansacNN = np.asarray(results_partials[1])\n",
    "\n",
    "ax1.plot(\n",
    "    RansacNN[:,0],\n",
    "    RansacNN[:,1],\n",
    "    \"-o\",\n",
    "    linewidth = linewidth,\n",
    "    fillstyle = 'none',\n",
    "    mew = linewidth,markersize = markersize,\n",
    "    label = \"NN-matcher\"\n",
    ")\n",
    "\n",
    "ax1.plot(\n",
    "    pointnetvlad[::2,0],\n",
    "    pointnetvlad[::2,1],\n",
    "    \":s\",\n",
    "    linewidth = linewidth,fillstyle = 'right',\n",
    "    mew = linewidth,markersize = markersize,\n",
    "    label = \"pointnetvlad\"\n",
    ")\n",
    "\n",
    "ax1.legend(loc = \"upper right\", ncol = 2, fontsize = 8);\n",
    "\n",
    "ax2 = fig.add_subplot(122) \n",
    "\n",
    "ax2.grid(alpha = 0.7)\n",
    "ax2.set_ylim(-0.25,10.25)\n",
    "ax2.set_xlim(0,3)\n",
    "\n",
    "ax2.set_ylabel(\"INTRA-space Privacy, $\\Pi_2$ (m)\", fontsize = 14)\n",
    "ax1.set_xlabel(\"Partial Radius (m)\", fontsize = 14)\n",
    "\n",
    "ax2.plot(\n",
    "    RansacNN[:,0],\n",
    "    RansacNN[:,2],\n",
    "    '-.o',\n",
    "    linewidth = linewidth,\n",
    "    fillstyle = 'none',\n",
    "    mew = linewidth,markersize = markersize,\n",
    "    label = \"NN-matcher\"\n",
    ")\n",
    "\n",
    "ax2.plot(\n",
    "    pointnetvlad[::2,0],\n",
    "    pointnetvlad[::2,2],\n",
    "    \":s\",\n",
    "    linewidth = linewidth,fillstyle = 'right',\n",
    "    mew = linewidth,markersize = markersize,\n",
    "    label = \"pointnetvlad\"\n",
    ")\n",
    "\n",
    "ax2.legend(loc = \"upper right\", ncol = 2, fontsize = 8);\n",
    "\n",
    "#plt.savefig('plots/partials-radius-with-pointnetvlad.png', format='png', dpi=300,bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Successive case: spatial inference using pointnetvlad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for radius in np.arange(0.5,2.1,0.5):\n",
    "    \n",
    "    pickle_file = 'successive_results_'+str(radius)+'_updated_refs.pickle'\n",
    "\n",
    "    try:\n",
    "        with open(RESULTS_FOLDER + pickle_file,'rb') as pickle_output:\n",
    "            results_pickle = pickle.load(pickle_output)\n",
    "    except:\n",
    "        print(\"No \"+pickle_file+\" file yet.\")\n",
    "        results_pickle = []\n",
    "\n",
    "    successive_path = 'successive_radius_'+str(radius)\n",
    "    \n",
    "    for release in np.arange(1,100,5):\n",
    "\n",
    "        query_fol = 'release_'+str(release)\n",
    "\n",
    "        QUERY_FILE = 'pointnetvlad_submaps/successive_queries_updated_refs/3d_jittered_{}_evaluation_query.pickle'.format(successive_path+\"_\"+query_fol)\n",
    "\n",
    "        output_file = RESULTS_FOLDER +pickle_file+query_fol+'.txt'\n",
    "\n",
    "        QUERY_SETS= get_sets_dict(QUERY_FILE)\n",
    "\n",
    "        query_partial_path = os.path.join(QUERY_PATH,successive_path,query_fol)\n",
    "\n",
    "        df_test= pd.read_csv(os.path.join(query_partial_path,\"pointcloud_centroids_4m.csv\"),sep=',')\n",
    "\n",
    "        QUERY_DATABASE_NUMPY = np.asarray(df_test)\n",
    "\n",
    "        print(\"Doing\",QUERY_FILE,query_partial_path)\n",
    "\n",
    "        ave_recall, ave_intra_dist = evaluate(QUERY_SETS, QUERY_DATABASE_NUMPY, output_file)\n",
    "\n",
    "        results_pickle.append([\n",
    "                release,\n",
    "                ave_recall,\n",
    "                ave_intra_dist\n",
    "            ])\n",
    "\n",
    "        with open(RESULTS_FOLDER + pickle_file,'wb') as pickle_output:\n",
    "            pickle.dump(results_pickle,pickle_output)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results: Successive case with pointnetVLAD (vs NN-matcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointnetvlad_successive = []\n",
    "\n",
    "for radius in np.arange(0.5,2.1,0.5):\n",
    "    \n",
    "    pickle_file = 'successive_results_'+str(radius)+'_updated_refs.pickle'\n",
    "\n",
    "    pointnetvlad_successive_per_radius = []\n",
    "\n",
    "    try:\n",
    "        with open(RESULTS_FOLDER + pickle_file,'rb') as pickle_output:\n",
    "            results_pickle = pickle.load(pickle_output)\n",
    "    except:\n",
    "        print(\"No results_ransac.\")\n",
    "\n",
    "    for release, recall, intra_dist in results_pickle:\n",
    "        pointnetvlad_successive_per_radius.append([\n",
    "            release,\n",
    "            recall[0],\n",
    "            intra_dist[0]\n",
    "        ])\n",
    "\n",
    "    pointnetvlad_successive_per_radius = np.asarray(pointnetvlad_successive_per_radius)#[-16:]\n",
    "\n",
    "    pointnetvlad_successive.append(pointnetvlad_successive_per_radius)\n",
    "    \n",
    "with open('testing_results/successive/nn_matcher_errors.pickle', 'rb') as f:\n",
    "    [succ_NN_errors,succ_NN_intra_errors] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(12, 3))\n",
    "\n",
    "ax1 = fig.add_subplot(121) \n",
    "\n",
    "ax1.grid(alpha = 0.7)\n",
    "ax1.set_ylim(-0.025,1.025)\n",
    "ax1.set_xlim(0,100)\n",
    "ax1.set_ylabel(\"INTER-space Privacy, $\\Pi_1$\", fontsize = 14)\n",
    "ax1.set_xlabel(\"Number of Releases\", fontsize = 14)\n",
    "\n",
    "markersize = 7\n",
    "linewidth = 1.5\n",
    "#plt.minorticks_on()\n",
    "\n",
    "for radius, inter_errors in succ_NN_errors:#[:2]:\n",
    "\n",
    "    if radius == 1.5: continue\n",
    "\n",
    "    #print(RawNN_per_iteration_errors.shape)\n",
    "    ax1.plot(\n",
    "        np.arange(1,100,10)[:len(inter_errors):]+1,\n",
    "        inter_errors[::], \n",
    "        '-o', \n",
    "        linewidth = linewidth,fillstyle = 'none',\n",
    "        mew = linewidth,markersize = min(markersize*(1.25/radius),markersize),\n",
    "        label = \"NN-matcher, r =\"+ str(radius)\n",
    "    )\n",
    "\n",
    "for i, radius in enumerate(np.arange(0.5,2.1,0.5)):\n",
    "\n",
    "    if radius == 1.5: continue\n",
    "\n",
    "    ax1.plot(\n",
    "        np.arange(1,100,10)+1,\n",
    "        pointnetvlad_successive[i][::2,1],\n",
    "        \":s\",\n",
    "        linewidth = linewidth,fillstyle = 'none',\n",
    "        mew = linewidth,markersize = min(markersize*(1.25/radius),markersize),\n",
    "        label = \"pointnetvlad, r = \"+str(radius)\n",
    "    )\n",
    "\n",
    "ax1.legend(loc = \"upper right\", ncol = 2, fontsize = 8);\n",
    "\n",
    "ax2 = fig.add_subplot(122) \n",
    "\n",
    "ax2.grid(alpha = 0.7)\n",
    "ax2.set_ylim(-0.25,10.25)\n",
    "ax2.set_xlim(0,100)\n",
    "\n",
    "ax2.set_ylabel(\"INTRA-space Privacy, $\\Pi_2$ (m)\", fontsize = 14)\n",
    "ax2.set_xlabel(\"Number of Releases\", fontsize = 14)\n",
    "\n",
    "for radius, intra_errors in succ_NN_intra_errors:#[:2]:\n",
    "    \n",
    "    if radius == 1.5: continue\n",
    "    \n",
    "    ax2.plot(\n",
    "        np.arange(1,100,10)+1,#[:len(intra_errors):2]+1,\n",
    "        intra_errors[::,0], \n",
    "        '-o',\n",
    "        linewidth = linewidth, #capsize = 4.0, \n",
    "        #marker = markers[0],\n",
    "        fillstyle = 'none',\n",
    "        mew = linewidth,markersize = min(markersize*(1.25/radius),markersize),\n",
    "        label = \"NN-matcher, r =\"+ str(radius)\n",
    "    )\n",
    "\n",
    "for i, radius in enumerate(np.arange(0.5,2.1,0.5)):\n",
    "\n",
    "    if radius == 1.5: continue\n",
    "\n",
    "    ax2.plot(\n",
    "        np.arange(1,100,10)+1,\n",
    "        pointnetvlad_successive[i][::2,2],\n",
    "        \":s\",\n",
    "        linewidth = linewidth,fillstyle = 'none',\n",
    "        mew = linewidth,markersize = min(markersize*(1.25/radius),markersize),\n",
    "        label = \"pointnetvlad, r = \"+str(radius)\n",
    "    )\n",
    "\n",
    "\n",
    "ax2.legend(loc = \"upper right\", ncol = 2, fontsize = 8);\n",
    "\n",
    "plt.savefig('plots/successive-with-pointnetvlad.png', format='png', dpi=300,bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-mr-environment]",
   "language": "python",
   "name": "conda-env-.conda-mr-environment-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
