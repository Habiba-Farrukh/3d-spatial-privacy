{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import time\n",
    "import h5py\n",
    "import bz2\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "\n",
    "from numpy import linalg as LA\n",
    "from scipy.spatial import Delaunay\n",
    "from sklearn.neighbors import NearestNeighbors, KDTree\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "#sys.path.insert(0, \"../\")\n",
    "from info3d import *\n",
    "from nn_matchers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the point collection and the descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('point_collection/new_contiguous_point_collection.pickle','rb') as f: \n",
    "    new_contiguous_point_collection = pickle.load(f)\n",
    "    \n",
    "with open('descriptors/new_complete_res5_4by5_descriptors.pickle','rb') as f:\n",
    "    descriptors = pickle.load(f)\n",
    "    \n",
    "with open('descriptors/new_complete_RANSAC_res5_4by5_descriptors.pickle','rb') as f:\n",
    "    ransac_descriptors = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use only a 300 samples for this.\n",
    "with open('sample_points.pickle','rb') as f:\n",
    "    sample_points = pickle.load(f)\n",
    "    \n",
    "sample_points_300 = np.random.choice(1000,300,False)\n",
    "\n",
    "len(sample_points), len(sample_points_300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1.1: Raw spaces (validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "descriptors = descriptors\n",
    "\n",
    "for radius in np.arange(0.25,3.1,0.5):\n",
    "    \n",
    "    t0 = time.time()\n",
    "    t1 = time.time()\n",
    "        \n",
    "    partial_scores_pool = []\n",
    "    \n",
    "    print(\"radius =\",radius)\n",
    "    \n",
    "    for s_i in sample_points_300:\n",
    "        \n",
    "        t3 = time.time()\n",
    "        \n",
    "        obj_, object_name, original_vertex = sample_points[s_i]\n",
    "        \n",
    "        pointCloud = []\n",
    "        \n",
    "        try:\n",
    "            object_, pointCloud_, tri_ = new_contiguous_point_collection[int(obj_)]\n",
    "            \n",
    "            ransac_nbrs = NearestNeighbors(n_neighbors=min(20000,len(pointCloud_)), algorithm='kd_tree').fit(pointCloud_[:,:3])\n",
    "            \n",
    "            dist_, ind_ = ransac_nbrs.kneighbors([original_vertex[:3]])\n",
    "            pointCloud =  pointCloud_[ind_[0,np.where(dist_[0,:]<=radius)[0]]]\n",
    "        except:\n",
    "            print(\"Can't get partial samples for\",obj_meta[0])\n",
    "            continue\n",
    "            \n",
    "        #if len(gen_planes) == 0: continue\n",
    "        if len(pointCloud) == 0: continue\n",
    "\n",
    "        local_keypoint_matches = []\n",
    "\n",
    "        try:\n",
    "            obj_meta, diff_ratios, diff_indexs, diff_scores, local_keypoint_matches = get_score_kdtree_lean(\n",
    "                [obj_, object_name, original_vertex], \n",
    "                pointCloud, \n",
    "                descriptors\n",
    "            )\n",
    "            \n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "            print(\"skipped\",object_name)\n",
    "            continue\n",
    "        \n",
    "        if len(local_keypoint_matches) == 0: \n",
    "            print(0,\"skipped\",object_name)\n",
    "            continue\n",
    "\n",
    "        partial_scores_pool.append([\n",
    "            [obj_, object_name, original_vertex], \n",
    "            diff_ratios,\n",
    "            diff_indexs,\n",
    "            diff_scores,\n",
    "            local_keypoint_matches\n",
    "        ])\n",
    "        \n",
    "        t4 = time.time()\n",
    "\n",
    "        if len(partial_scores_pool) % 66 == 2:\n",
    "            \n",
    "            partial_errors_pool = NN_matcher(partial_scores_pool)\n",
    "            print(\"  \",radius,\": Done with {}, in {:.3f} seconds. Error rate {:.3f}\".format(\n",
    "                len(partial_scores_pool),\n",
    "                time.time()-t1,\n",
    "                np.sum(partial_errors_pool[:,1])/len(partial_scores_pool)\n",
    "            ))\n",
    "                 \n",
    "            with bz2.BZ2File('testing_results/partial/raw_{}_partial_scores.pickle.bz2'.format(radius), 'w') as bz2_f:\n",
    "                pickle.dump(partial_scores_pool, bz2_f)\n",
    "            \n",
    "            t1  = time.time()\n",
    "\n",
    "    print(radius,\" Total Time to match {:.3f} seconds.\".format(time.time()-t0))\n",
    "    \n",
    "    #print(len(partial_lengths))\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1.2: RANSAC-generalized spaces validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = descriptors\n",
    "\n",
    "for radius in np.arange(2.25,3.1,0.5):\n",
    "    \n",
    "    t0 = time.time()\n",
    "    t1 = time.time()\n",
    "    \n",
    "    partial_scores_pool = []\n",
    "    \n",
    "    print(\"radius =\",radius)\n",
    "    \n",
    "    for s_i in sample_points_300:\n",
    "        \n",
    "        obj_, object_name, original_vertex = sample_points[s_i]\n",
    "        \n",
    "        pointCloud = []\n",
    "        \n",
    "        try:\n",
    "            trial = np.random.randint(5)\n",
    "            \n",
    "            with open(\"../ransac_pc/ransac_point_collection_{}.pickle\".format(trial),'rb') as f:\n",
    "                ransac_trial_point_collection = pickle.load(f)\n",
    "\n",
    "            object_, pointCloud_, tri_ = ransac_trial_point_collection[int(obj_)]\n",
    "            \n",
    "            ransac_nbrs = NearestNeighbors(n_neighbors=min(20000,len(pointCloud_)), algorithm='kd_tree').fit(pointCloud_[:,:3])\n",
    "            \n",
    "            dist_, ind_ = ransac_nbrs.kneighbors([original_vertex[:3]])\n",
    "            pointCloud =  pointCloud_[ind_[0,np.where(dist_[0,:]<=radius)[0]]]\n",
    "        except:\n",
    "            print(\"Can't get ransac samples for\",trial,obj_meta[0],dist_.shape,ind_.shape)\n",
    "            continue\n",
    "            \n",
    "        #if len(gen_planes) == 0: continue\n",
    "        if len(pointCloud) == 0: continue\n",
    "\n",
    "        local_keypoint_matches = []\n",
    "\n",
    "        try:\n",
    "            obj_meta, diff_ratios, diff_indexs, diff_scores, local_keypoint_matches = get_score_kdtree_lean(\n",
    "                [obj_, object_name, original_vertex], \n",
    "                pointCloud, \n",
    "                descriptors\n",
    "            )\n",
    "            \n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "            print(\"skipped\",object_name)\n",
    "            continue\n",
    "        \n",
    "        if len(local_keypoint_matches) == 0: \n",
    "            print(\"skipped\",object_name)\n",
    "            continue\n",
    "\n",
    "        partial_scores_pool.append([\n",
    "            [obj_, object_name, original_vertex], \n",
    "            diff_ratios,\n",
    "            diff_indexs,\n",
    "            diff_scores,\n",
    "            local_keypoint_matches\n",
    "        ])\n",
    "\n",
    "        if len(partial_scores_pool) % 66 == 2:\n",
    "            \n",
    "            partial_errors_pool = NN_matcher(partial_scores_pool)\n",
    "            print(radius,\"Error Rate:\",)\n",
    "            \n",
    "            print(\"  \",radius,\": Done with {}, in {:.3f} seconds. Error rate {:.3f}\".format(\n",
    "                len(partial_scores_pool),\n",
    "                time.time()-t1,\n",
    "                np.sum(partial_errors_pool[:,1])/len(partial_scores_pool)\n",
    "            ))\n",
    "                        \n",
    "            with bz2.BZ2File('testing_results/partial/ransac_{}_partial_scores_parallel_sample_points.pickle.bz2'.format(radius), 'w') as bz2_f:\n",
    "                pickle.dump(partial_scores_pool, bz2_f)\n",
    "                \n",
    "            t1  = time.time()\n",
    "\n",
    "    print(radius,\" Total Time to match {:.3f} seconds.\".format(time.time()-t0))\n",
    "    \n",
    "\n",
    "    #print(len(partial_lengths))\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1.3: Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_partials = [[],[]] \n",
    "\n",
    "raw_errors = []    \n",
    "ransac_errors = []\n",
    "\n",
    "for radius in np.arange(0.25, 3.1, 0.5):\n",
    "\n",
    "    try:\n",
    "        with bz2.BZ2File('testing_results/partial/ransac_{}_partial_scores_parallel_sample_points.pickle.bz2'.format(radius), 'r') as bz2_f:\n",
    "            partial_scores_pool = pickle.load(bz2_f) \n",
    "\n",
    "    except:\n",
    "        print(\"Error getting Raw scores for\",radius)\n",
    "        continue\n",
    "\n",
    "    partial_errors_pool = NN_matcher(partial_scores_pool)\n",
    "    correct_interspace_labels_idxs = np.where(partial_errors_pool[:,1]==0)[0]\n",
    "    intraspace_errors  = partial_errors_pool[correct_interspace_labels_idxs,2]\n",
    "\n",
    "    print(radius,\"(Ransac) P1 Error Rate:\",np.sum(partial_errors_pool[:,1])/len(partial_scores_pool)) \n",
    "    print(\"   (Ransac) P2 Error Rate: {:.3f} (± {:.3f})\".format(np.nanmean(intraspace_errors),np.nanstd(intraspace_errors))) \n",
    "    \n",
    "    ransac_errors.append([\n",
    "        radius,\n",
    "        partial_errors_pool\n",
    "    ])\n",
    "    \n",
    "    results_partials[1].append([\n",
    "        radius,\n",
    "        np.sum(partial_errors_pool[:,1])/len(partial_scores_pool),\n",
    "        np.nanmean(intraspace_errors),\n",
    "        np.nanstd(intraspace_errors)\n",
    "    ])\n",
    "    \n",
    "    try:\n",
    "        with bz2.BZ2File('testing_results/partial/raw_{}_partial_scores.pickle.bz2'.format(radius), 'r') as bz2_f:\n",
    "            partial_scores_pool = pickle.load(bz2_f) \n",
    "            \n",
    "    except:\n",
    "        print(\"Error getting Raw scores for\",radius)\n",
    "        continue\n",
    "\n",
    "    partial_errors_pool = NN_matcher(partial_scores_pool)\n",
    "    correct_interspace_labels_idxs = np.where(partial_errors_pool[:,1]==0)[0]\n",
    "    intraspace_errors  = partial_errors_pool[correct_interspace_labels_idxs,2]\n",
    "\n",
    "    print(radius,\"(Raw) P1 Error Rate:\",np.sum(partial_errors_pool[:,1])/len(partial_scores_pool)) \n",
    "    print(\"   (Raw) P2 Error Rate: {:.3f} (± {:.3f})\".format(np.nanmean(intraspace_errors),np.nanstd(intraspace_errors))) \n",
    "    \n",
    "    results_partials[0].append([\n",
    "        radius,\n",
    "        np.sum(partial_errors_pool[:,1])/len(partial_scores_pool),\n",
    "        np.nanmean(intraspace_errors),\n",
    "        np.nanstd(intraspace_errors)\n",
    "    ])\n",
    "    \n",
    "    raw_errors.append([\n",
    "        radius,\n",
    "        partial_errors_pool\n",
    "    ])\n",
    "    \n",
    "with open('testing_results/partial/results_partials_nn_matcher.pickle', 'wb') as f:\n",
    "    pickle.dump(results_partials,f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(15, 3.25))\n",
    "\n",
    "RawNN = np.asarray(results_partials[0])\n",
    "RansacNN = np.asarray(results_partials[1])\n",
    "\n",
    "ax1 = fig.add_subplot(121) \n",
    "\n",
    "ax1.grid(alpha = 0.7)\n",
    "ax1.set_ylim(-0.025,1.025)\n",
    "ax1.set_xlim(0,2.0)\n",
    "ax1.set_ylabel(\"INTER-space Privacy\")\n",
    "ax1.set_xlabel(\"Partial Radius\")\n",
    "\n",
    "markersize = 7\n",
    "linewidth = 1.5\n",
    "\n",
    "ax1.plot(\n",
    "    RawNN[:,0],RawNN[:,1],\n",
    "    \":o\",\n",
    "    linewidth = linewidth,fillstyle = 'left',\n",
    "    mew = linewidth,markersize = markersize,\n",
    "    label = \"NN-matcher, Raw\"\n",
    ")\n",
    "ax1.plot(\n",
    "    RansacNN[:,0],\n",
    "    RansacNN[:,1],\n",
    "    \"-s\",\n",
    "    linewidth = linewidth,\n",
    "    fillstyle = 'none',\n",
    "    mew = linewidth,markersize = markersize,\n",
    "    label = \"NN-matcher, Generalized\"\n",
    ")\n",
    "\n",
    "\n",
    "ax1.legend(loc = \"upper right\", ncol = 1, fontsize = 10);# bbox_to_anchor=(1.1, 1.5));\n",
    "\n",
    "ax2 = fig.add_subplot(122) \n",
    "\n",
    "ax2.grid(alpha = 0.7)\n",
    "ax2.set_ylim(-0.25,10.25)\n",
    "ax2.set_xlim(0,2)\n",
    "\n",
    "ax2.set_ylabel(\"INTRA-space Privacy (m)\")\n",
    "ax2.set_xlabel(\"Partial Radius (m)\")\n",
    "#ax2.set_yticklabels(fontsize = 16)\n",
    "#ax2.set_xticklabels(fontsize = 16)\n",
    "\n",
    "#plt.minorticks_on()\n",
    "\n",
    "ax2.plot(\n",
    "    RawNN[:,0],\n",
    "    RawNN[:,2], \n",
    "    linewidth = linewidth, \n",
    "    marker = 'o',fillstyle = 'none',\n",
    "    mew = linewidth,markersize = markersize,\n",
    "    label = \"NN-matcher, Raw\"\n",
    ")\n",
    "ax2.plot(\n",
    "    RansacNN[:,0],\n",
    "    RansacNN[:,2],\n",
    "    '-.s',\n",
    "    linewidth = linewidth,\n",
    "    fillstyle = 'none',\n",
    "    mew = linewidth,markersize = markersize,\n",
    "    label = \"NN-matcher, Generalized\"\n",
    ")\n",
    "\n",
    "ax2.legend(loc = \"upper right\", ncol = 1, fontsize = 10);#, bbox_to_anchor=(1.1, 1.5));\n",
    "\n",
    "plt.savefig('plots/one-time-partials-spaces.png', format='png', dpi=300,bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-3d_env] *",
   "language": "python",
   "name": "conda-env-.conda-3d_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
