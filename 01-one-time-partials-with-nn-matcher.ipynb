{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import time\n",
    "import h5py\n",
    "import bz2\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "\n",
    "from numpy import linalg as LA\n",
    "from scipy.spatial import Delaunay\n",
    "from sklearn.neighbors import NearestNeighbors, KDTree\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "#sys.path.insert(0, \"../\")\n",
    "from info3d import *\n",
    "from nn_matchers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the point collection and the descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('point_collection/new_contiguous_point_collection.pickle','rb') as f: \n",
    "    new_contiguous_point_collection = pickle.load(f)\n",
    "    \n",
    "with open('descriptors/new_complete_res5_4by5_descriptors.pickle','rb') as f:\n",
    "    descriptors = pickle.load(f)\n",
    "    \n",
    "with open('descriptors/new_complete_RANSAC_res5_4by5_descriptors.pickle','rb') as f:\n",
    "    ransac_descriptors = pickle.load(f)\n",
    "    \n",
    "with open('point_collection/2_filled_quaternion_vertical_correction_arcore_point_cloud_collection_complete.pickle','rb') as f: \n",
    "    arcore_point_cloud_collection = pickle.load(f)\n",
    "    \n",
    "with open('descriptors/chosen_arcore_res5_4by5_descriptors_complete.pickle','rb') as f:\n",
    "    arcore_descriptors = pickle.load(f)\n",
    "    \n",
    "results_path = 'testing_results'\n",
    "\n",
    "if not os.path.exists(results_path): os.mkdir(results_path)\n",
    "\n",
    "partial_results_path = os.path.join(results_path,\"partial\")\n",
    "successive_results_path = os.path.join(results_path,\"successive\")\n",
    "\n",
    "if not os.path.exists(partial_results_path): os.mkdir(partial_results_path)\n",
    "if not os.path.exists(successive_results_path): os.mkdir(successive_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use only a 300 samples for this.\n",
    "with open('sample_points.pickle','rb') as f:\n",
    "    sample_points = pickle.load(f)\n",
    "    \n",
    "#sample_points_300 = np.random.choice(1000,300,False)\n",
    "    \n",
    "with open('sample_arcore_points.pickle','rb') as f:\n",
    "    sample_arcore_points = pickle.load(f)\n",
    "    \n",
    "arcore_spaces = [[],[],[],[],[],[],[]]\n",
    "    \n",
    "for [obj_num, name, timestamp], t_pointCloud, triangles in arcore_point_cloud_collection:\n",
    "    \n",
    "    unique_normals = np.unique(np.around(t_pointCloud[:,3:],decimals = 2),axis = 0)\n",
    "    \n",
    "    #print(obj_num, name, timestamp, len(unique_normals))\n",
    "    try:\n",
    "        arcore_spaces[int(obj_num)].append([\n",
    "            [obj_num, name, timestamp],\n",
    "            t_pointCloud, \n",
    "            triangles,\n",
    "            len(unique_normals)\n",
    "        ])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1.1: HoloLens Raw spaces (validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = descriptors\n",
    "\n",
    "for radius in np.arange(0.25,3.1,0.5):\n",
    "    \n",
    "    t0 = time.time()\n",
    "    t1 = time.time()\n",
    "        \n",
    "    partial_scores_pool = []\n",
    "    \n",
    "    print(\"radius =\",radius)\n",
    "    \n",
    "    for obj_, object_name, original_vertex in sample_points:\n",
    "        \n",
    "        t3 = time.time()\n",
    "        \n",
    "        #obj_, object_name, original_vertex = sample_points[s_i]\n",
    "        \n",
    "        pointCloud = []\n",
    "        \n",
    "        try:\n",
    "            object_, pointCloud_, tri_ = new_contiguous_point_collection[int(obj_)]\n",
    "            \n",
    "            ransac_nbrs = NearestNeighbors(n_neighbors=min(20000,len(pointCloud_)), algorithm='kd_tree').fit(pointCloud_[:,:3])\n",
    "            \n",
    "            dist_, ind_ = ransac_nbrs.kneighbors([original_vertex[:3]])\n",
    "            pointCloud =  pointCloud_[ind_[0,np.where(dist_[0,:]<=radius)[0]]]\n",
    "        except:\n",
    "            print(\"Can't get partial samples for\",obj_meta[0])\n",
    "            continue\n",
    "            \n",
    "        #if len(gen_planes) == 0: continue\n",
    "        if len(pointCloud) == 0: continue\n",
    "\n",
    "        local_keypoint_matches = []\n",
    "\n",
    "        try:\n",
    "            obj_meta, diff_ratios, diff_indexs, diff_scores, local_keypoint_matches = get_score_kdtree_lean(\n",
    "                [obj_, object_name, original_vertex], \n",
    "                pointCloud, \n",
    "                descriptors\n",
    "            )\n",
    "            \n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "            print(\"skipped\",object_name)\n",
    "            continue\n",
    "        \n",
    "        if len(local_keypoint_matches) == 0: \n",
    "            print(0,\"skipped\",object_name)\n",
    "            continue\n",
    "\n",
    "        partial_scores_pool.append([\n",
    "            [obj_, object_name, original_vertex], \n",
    "            diff_ratios,\n",
    "            diff_indexs,\n",
    "            diff_scores,\n",
    "            local_keypoint_matches\n",
    "        ])\n",
    "        \n",
    "        t4 = time.time()\n",
    "\n",
    "        if len(partial_scores_pool) % 66 == 2:\n",
    "            \n",
    "            partial_errors_pool = NN_matcher(partial_scores_pool)\n",
    "            print(\"  \",radius,\": Done with {}, in {:.3f} seconds. Error rate {:.3f}\".format(\n",
    "                len(partial_scores_pool),\n",
    "                time.time()-t1,\n",
    "                np.sum(partial_errors_pool[:,1])/len(partial_scores_pool)\n",
    "            ))\n",
    "                 \n",
    "            with bz2.BZ2File('testing_results/partial/raw_{}_partial_scores.pickle.bz2'.format(radius), 'w') as bz2_f:\n",
    "                pickle.dump(partial_scores_pool, bz2_f)\n",
    "            \n",
    "            t1  = time.time()\n",
    "\n",
    "    print(radius,\" Total Time to match {:.3f} seconds.\".format(time.time()-t0))\n",
    "    \n",
    "    #print(len(partial_lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1.2: RANSAC-generalized HoloLens spaces evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "descriptors = descriptors\n",
    "\n",
    "for radius in np.arange(0.5,5.1,0.5):\n",
    "    \n",
    "    t0 = time.time()\n",
    "    t1 = time.time()\n",
    "    \n",
    "    partial_scores_pool = []\n",
    "    \n",
    "    print(\"radius =\",radius)\n",
    "    \n",
    "    for obj_, object_name, original_vertex in sample_points: #[s_i]\n",
    "        \n",
    "        pointCloud = []\n",
    "        \n",
    "        try:\n",
    "            trial = np.random.randint(5)\n",
    "            \n",
    "            with open(\"../ransac_pc/ransac_point_collection_{}.pickle\".format(trial),'rb') as f:\n",
    "                ransac_trial_point_collection = pickle.load(f)\n",
    "\n",
    "            object_, pointCloud_, tri_ = ransac_trial_point_collection[int(obj_)]\n",
    "            \n",
    "            ransac_nbrs = NearestNeighbors(n_neighbors=min(20000,len(pointCloud_)), algorithm='kd_tree').fit(pointCloud_[:,:3])\n",
    "            \n",
    "            dist_, ind_ = ransac_nbrs.kneighbors([original_vertex[:3]])\n",
    "            pointCloud =  pointCloud_[ind_[0,np.where(dist_[0,:]<=radius)[0]]]\n",
    "        except:\n",
    "            print(\"Can't get ransac samples for\",trial,obj_meta[0],dist_.shape,ind_.shape)\n",
    "            continue\n",
    "            \n",
    "        #if len(gen_planes) == 0: continue\n",
    "        if len(pointCloud) == 0: continue\n",
    "\n",
    "        local_keypoint_matches = []\n",
    "\n",
    "        try:\n",
    "            obj_meta, diff_ratios, diff_indexs, diff_scores, local_keypoint_matches = get_score_kdtree_lean(\n",
    "                [obj_, object_name, original_vertex], \n",
    "                pointCloud, \n",
    "                descriptors,\n",
    "                desc_new=True,\n",
    "                old = True\n",
    "            )\n",
    "            \n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "            print(\"skipped\",object_name)\n",
    "            continue\n",
    "        \n",
    "        if len(local_keypoint_matches) == 0: \n",
    "            print(\"skipped\",object_name)\n",
    "            continue\n",
    "\n",
    "        partial_scores_pool.append([\n",
    "            [obj_, object_name, original_vertex], \n",
    "            diff_ratios,\n",
    "            diff_indexs,\n",
    "            diff_scores,\n",
    "            local_keypoint_matches\n",
    "        ])\n",
    "\n",
    "        if len(partial_scores_pool) % 66 == 2:\n",
    "            \n",
    "            partial_errors_pool = NN_matcher(partial_scores_pool)\n",
    "            print(radius,\"Error Rate:\",)\n",
    "            \n",
    "            print(\"  \",radius,\": Done with {}, in {:.3f} seconds. Error rate {:.3f}\".format(\n",
    "                len(partial_scores_pool),\n",
    "                time.time()-t1,\n",
    "                np.sum(partial_errors_pool[:,1])/len(partial_scores_pool)\n",
    "            ))\n",
    "\n",
    "            t1  = time.time()\n",
    "                        \n",
    "            with bz2.BZ2File('testing_results/partial/ransac_{}_partial_scores_parallel_sample_points_2.pickle.bz2'.format(radius), 'w') as bz2_f:\n",
    "                pickle.dump(partial_scores_pool, bz2_f)\n",
    "                \n",
    "    with bz2.BZ2File('testing_results/partial/ransac_{}_partial_scores_parallel_sample_points_2.pickle.bz2'.format(radius), 'w') as bz2_f:\n",
    "        pickle.dump(partial_scores_pool, bz2_f)\n",
    "\n",
    "    print(radius,\" Total Time to match {:.3f} seconds.\".format(time.time()-t0))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1.3: ARCore spaces evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCORE_RESULTS_FOLDER =\"testing_results/nn_matcher_arcore/\"\n",
    "if not os.path.exists(ARCORE_RESULTS_FOLDER): os.mkdir(ARCORE_RESULTS_FOLDER)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = arcore_descriptors[:-1]\n",
    "\n",
    "partial_results_path = os.path.join(RESULTS_FOLDER,\"partial\")\n",
    "\n",
    "if not os.path.exists(partial_results_path): os.mkdir(partial_results_path)\n",
    "    \n",
    "exp_eval_propeties = []\n",
    "\n",
    "for radius in np.arange(0.25,5.1,0.25):\n",
    "    \n",
    "    t0 = time.time()\n",
    "    t1 = time.time()\n",
    "    \n",
    "    partial_scores_pool = []\n",
    "    per_radius_properties = []\n",
    "    \n",
    "    print(\"radius =\",radius)\n",
    "    \n",
    "    for obj_, obj_sample, object_name, original_vertex in sample_arcore_points:\n",
    "    #for s_i in sample_points_300:\n",
    "        \n",
    "        t3 = time.time()\n",
    "        \n",
    "        #obj_, object_name, original_vertex = sample_points[s_i]\n",
    "        \n",
    "        pointCloud = []\n",
    "        \n",
    "        try:\n",
    "            object_, ransac_pointCloud, tri_, u_n_ = arcore_spaces[obj_][obj_sample]\n",
    "            \n",
    "            ransac_nbrs = NearestNeighbors(n_neighbors=min(20000,len(ransac_pointCloud)), algorithm='kd_tree').fit(ransac_pointCloud[:,:3])\n",
    "            \n",
    "            dist_, ind_ = ransac_nbrs.kneighbors([original_vertex[:3]])\n",
    "            pointCloud =  ransac_pointCloud[ind_[0,np.where(dist_[0,:]<=radius)[0]]]\n",
    "            \n",
    "        except:\n",
    "            print(\"Can't get ransac samples for\",trial,obj_meta[0],dist_.shape,ind_.shape)\n",
    "            continue\n",
    "            \n",
    "        #if len(gen_planes) == 0: continue\n",
    "        if len(pointCloud) == 0: continue\n",
    "\n",
    "        local_keypoint_matches = []\n",
    "\n",
    "        try:\n",
    "            obj_meta, diff_ratios, diff_indexs, diff_scores, local_keypoint_matches = get_score_kdtree_lean(\n",
    "                [obj_, object_name, original_vertex], \n",
    "                pointCloud, \n",
    "                descriptors,\n",
    "                desc_new=True,\n",
    "                old=True\n",
    "                #key_cap=keypoint_cap,\n",
    "                #strict_cap=True\n",
    "            )\n",
    "            \n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "            print(\"skipped\",object_name)\n",
    "            continue\n",
    "        \n",
    "        if len(local_keypoint_matches) == 0: \n",
    "            print(\"skipped\",object_name)\n",
    "            continue\n",
    "\n",
    "        t4 = time.time()\n",
    "\n",
    "        partial_scores_pool.append([\n",
    "            [obj_, object_name, original_vertex], \n",
    "            diff_ratios,\n",
    "            diff_indexs,\n",
    "            diff_scores,\n",
    "            local_keypoint_matches\n",
    "        ])\n",
    "                \n",
    "        per_radius_properties.append([\n",
    "            diff_ratios.shape,\n",
    "            diff_indexs.shape,\n",
    "            diff_scores.shape,\n",
    "            t4 - t3\n",
    "        ])\n",
    "\n",
    "        if len(partial_scores_pool) % 66 == 2:\n",
    "            \n",
    "            partial_errors_pool = ARcore_NNMatcher(partial_scores_pool, descriptors)\n",
    "            print(\"  \",radius,\": Done with {}, in {:.3f} seconds. Error rate {:.3f}\".format(\n",
    "                len(partial_scores_pool),\n",
    "                time.time()-t1,\n",
    "                np.sum(partial_errors_pool[:,1])/len(partial_scores_pool)\n",
    "            ))\n",
    "            print(\"  \",\n",
    "                  diff_ratios.shape,\n",
    "                  diff_indexs.shape,\n",
    "                  diff_scores.shape,\n",
    "                  \"in {:.3f} seconds\".format(t4 - t3)\n",
    "                 )\n",
    "                        \n",
    "            with bz2.BZ2File(ARCORE_RESULTS_FOLDER+'{}_partial_scores.pickle.bz2'.format(radius), 'w') as bz2_f:\n",
    "                pickle.dump(partial_scores_pool, bz2_f)\n",
    "                \n",
    "            t1  = time.time()\n",
    "\n",
    "    print(radius,\" Total Time to match {:.3f} seconds.\".format(time.time()-t0))\n",
    "    \n",
    "    #print(len(partial_lengths))\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1.4: Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Hololens data\n",
    "\n",
    "results_partials = [[],[]] \n",
    "\n",
    "raw_errors = []    \n",
    "ransac_errors = []\n",
    "\n",
    "for radius in np.arange(0.25, 5.1, 0.25):\n",
    "\n",
    "    try:\n",
    "        with bz2.BZ2File('testing_results/partial/ransac_{}_partial_scores_parallel_sample_points_2.pickle.bz2'.format(radius), 'r') as bz2_f:\n",
    "            partial_scores_pool = pickle.load(bz2_f) \n",
    "\n",
    "    except:\n",
    "        print(\"Error getting Raw scores for\",radius)\n",
    "        continue\n",
    "\n",
    "    partial_errors_pool = NN_matcher(partial_scores_pool)\n",
    "    correct_interspace_labels_idxs = np.where(partial_errors_pool[:,1]==0)[0]\n",
    "    intraspace_errors  = partial_errors_pool[correct_interspace_labels_idxs,2]\n",
    "\n",
    "    print(radius,\"(Ransac) P1 Error Rate:\",np.sum(partial_errors_pool[:,1])/len(partial_scores_pool)) \n",
    "    print(\"   (Ransac) P2 Error Rate: {:.3f} (± {:.3f})\".format(np.nanmean(intraspace_errors),np.nanstd(intraspace_errors))) \n",
    "    \n",
    "    ransac_errors.append([\n",
    "        radius,\n",
    "        partial_errors_pool\n",
    "    ])\n",
    "    \n",
    "    results_partials[1].append([\n",
    "        radius,\n",
    "        np.sum(partial_errors_pool[:,1])/len(partial_scores_pool),\n",
    "        np.nanmean(intraspace_errors),\n",
    "        np.nanstd(intraspace_errors)\n",
    "    ])\n",
    "    \n",
    "    try:\n",
    "        with bz2.BZ2File('testing_results/partial/raw_{}_partial_scores.pickle.bz2'.format(radius), 'r') as bz2_f:\n",
    "            partial_scores_pool = pickle.load(bz2_f) \n",
    "            \n",
    "    except:\n",
    "        print(\"Error getting Raw scores for\",radius)\n",
    "        continue\n",
    "\n",
    "    partial_errors_pool = NN_matcher(partial_scores_pool)\n",
    "    correct_interspace_labels_idxs = np.where(partial_errors_pool[:,1]==0)[0]\n",
    "    intraspace_errors  = partial_errors_pool[correct_interspace_labels_idxs,2]\n",
    "\n",
    "    print(radius,\"(Raw) P1 Error Rate:\",np.sum(partial_errors_pool[:,1])/len(partial_scores_pool)) \n",
    "    print(\"   (Raw) P2 Error Rate: {:.3f} (± {:.3f})\".format(np.nanmean(intraspace_errors),np.nanstd(intraspace_errors))) \n",
    "    \n",
    "    results_partials[0].append([\n",
    "        radius,\n",
    "        np.sum(partial_errors_pool[:,1])/len(partial_scores_pool),\n",
    "        np.nanmean(intraspace_errors),\n",
    "        np.nanstd(intraspace_errors)\n",
    "    ])\n",
    "    \n",
    "    raw_errors.append([\n",
    "        radius,\n",
    "        partial_errors_pool\n",
    "    ])\n",
    "    \n",
    "with open('testing_results/partial/results_partials_nn_matcher_1000.pickle', 'wb') as f:\n",
    "    pickle.dump([results_partials, raw_errors, ransac_errors],f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results for ARCore dataset\n",
    "\n",
    "arcore_results_partials = []\n",
    "\n",
    "arcore_errors = []\n",
    "\n",
    "for radius in np.arange(0.25, 3.1, 0.25):\n",
    "\n",
    "    try:\n",
    "        with bz2.BZ2File(\"testing_results/nn_matcher_arcore/{}_partial_scores.pickle.bz2\".format(radius), 'r') as bz2_f:\n",
    "            partial_scores_pool = pickle.load(bz2_f) \n",
    "\n",
    "    except:\n",
    "        print(\"Error getting arcore scores for\",radius)\n",
    "        continue\n",
    "\n",
    "    partial_errors_pool = ARcore_NNMatcher(partial_scores_pool, arcore_descriptors[:-1])\n",
    "    correct_interspace_labels_idxs = np.where(partial_errors_pool[:,1]==0)[0]\n",
    "    intraspace_errors  = partial_errors_pool[correct_interspace_labels_idxs,2]\n",
    "\n",
    "    print(radius,\"(Ransac) P1 Error Rate:\",np.sum(partial_errors_pool[:,1])/len(partial_scores_pool)) \n",
    "    print(\"   (Ransac) P2 Error Rate: {:.3f} (± {:.3f})\".format(np.nanmean(intraspace_errors),np.nanstd(intraspace_errors))) \n",
    "\n",
    "    arcore_results_partials.append([\n",
    "        radius,\n",
    "        np.sum(partial_errors_pool[:,1])/len(partial_scores_pool),\n",
    "        np.nanmean(intraspace_errors),\n",
    "        np.nanstd(intraspace_errors)\n",
    "    ])\n",
    "    \n",
    "    arcore_errors.append([\n",
    "        radius,\n",
    "        partial_errors_pool\n",
    "    ])\n",
    "    \n",
    "with open(\"testing_results/nn_matcher_arcore/results_partials_nn_matcher.pickle\", 'wb') as f:\n",
    "    pickle.dump([arcore_results_partials, arcore_errors],f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(7.5, 7))\n",
    "\n",
    "with open('testing_results/partial/results_partials_nn_matcher_1000.pickle', 'rb') as f:\n",
    "    results_partials, raw_errors, ransac_errors = pickle.load(f)\n",
    "    \n",
    "with open(\"testing_results/nn_matcher_arcore/results_partials_nn_matcher.pickle\", 'wb') as f:\n",
    "    arcore_results_partials, arcore_errors = pickle.load(f)\n",
    "\n",
    "RawNN = np.asarray(results_partials[0])\n",
    "RansacNN = np.asarray(results_partials[1])\n",
    "ARCoreNN = np.asarray(arcore_results_partials)\n",
    "\n",
    "ax1 = fig.add_subplot(211) \n",
    "\n",
    "ax1.grid(alpha = 0.7)\n",
    "ax1.set_ylim(-0.025,1.025)\n",
    "ax1.set_xlim(0,2.0)\n",
    "ax1.set_ylabel(\"INTER-space Privacy\")\n",
    "ax1.set_xlabel(\"Partial Radius\")\n",
    "\n",
    "markersize = 7\n",
    "linewidth = 1.5\n",
    "\n",
    "ax1.plot(\n",
    "    RawNN[:,0],RawNN[:,1],\n",
    "    \":o\",\n",
    "    linewidth = linewidth,fillstyle = 'left',\n",
    "    mew = linewidth,markersize = markersize,\n",
    "    label = \"NN-matcher, Holo-Raw\"\n",
    ")\n",
    "ax1.plot(\n",
    "    RansacNN[:,0],\n",
    "    RansacNN[:,1],\n",
    "    \"-s\",\n",
    "    linewidth = linewidth,\n",
    "    fillstyle = 'none',\n",
    "    mew = linewidth,markersize = markersize,\n",
    "    label = \"NN-matcher, Holo-Gen\"\n",
    ")\n",
    "ax1.plot(\n",
    "    ARCoreNN[:,0],\n",
    "    ARCoreNN[:,1],\n",
    "    \"-^\",\n",
    "    linewidth = linewidth,\n",
    "    fillstyle = 'none',\n",
    "    mew = linewidth,markersize = markersize,\n",
    "    label = \"NN-matcher, ARCore\"\n",
    ")\n",
    "\n",
    "ax1.legend(loc = \"lower left\", ncol = 1, fontsize = 10);# bbox_to_anchor=(1.1, 1.5));\n",
    "\n",
    "ax2 = fig.add_subplot(212) \n",
    "\n",
    "ax2.grid(alpha = 0.7)\n",
    "ax2.set_ylim(-0.25,10.25)\n",
    "ax2.set_xlim(0,2)\n",
    "\n",
    "ax2.set_ylabel(\"INTRA-space Privacy (m)\")\n",
    "ax2.set_xlabel(\"Partial Radius (m)\")\n",
    "#ax2.set_yticklabels(fontsize = 16)\n",
    "#ax2.set_xticklabels(fontsize = 16)\n",
    "\n",
    "#plt.minorticks_on()\n",
    "\n",
    "ax2.plot(\n",
    "    RawNN[:,0],\n",
    "    RawNN[:,2], \n",
    "    linewidth = linewidth, \n",
    "    marker = 'o',fillstyle = 'none',\n",
    "    mew = linewidth,markersize = markersize,\n",
    "    label = \"NN-matcher, Holo-Raw\"\n",
    ")\n",
    "ax2.plot(\n",
    "    RansacNN[:,0],\n",
    "    RansacNN[:,2],\n",
    "    '-.s',\n",
    "    linewidth = linewidth,\n",
    "    fillstyle = 'none',\n",
    "    mew = linewidth,markersize = markersize,\n",
    "    label = \"NN-matcher, Holo-Gen\"\n",
    ")\n",
    "ax2.plot(\n",
    "    ARCoreNN[:,0],\n",
    "    ARCoreNN[:,2],\n",
    "    '-.^',\n",
    "    linewidth = linewidth,\n",
    "    fillstyle = 'none',\n",
    "    mew = linewidth,markersize = markersize,\n",
    "    label = \"NN-matcher, ARCore\"\n",
    ")\n",
    "\n",
    "ax2.legend(loc = \"upper right\", ncol = 1, fontsize = 10);\n",
    "plt.savefig('plots/one-time-partials-spaces.png', format='png', dpi=300,bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-3d_env] *",
   "language": "python",
   "name": "conda-env-.conda-3d_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
