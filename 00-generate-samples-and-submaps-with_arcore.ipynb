{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import time\n",
    "import h5py\n",
    "import csv\n",
    "\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "\n",
    "from numpy import linalg as LA\n",
    "from scipy.spatial import Delaunay\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "#sys.path.insert(0, \"../\")\n",
    "from info3d import *\n",
    "from nn_matchers import *\n",
    "\n",
    "from query_sets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Global parameters\n",
    "\n",
    "radius_range = np.arange(0.5,1.6,0.5)\n",
    "\n",
    "with open('point_collection/new_contiguous_point_collection.pickle','rb') as f: \n",
    "    new_contiguous_point_collection = pickle.load(f)\n",
    "\n",
    "point_collection_indices = np.arange(len(new_contiguous_point_collection))\n",
    "point_collection_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.3: Create submaps for pointnetvlad using same samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_span = 2.0\n",
    "\n",
    "interval = 0.5\n",
    "\n",
    "num_points = 4096\n",
    "\n",
    "cutoff = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7, 7)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "with open('point_collection/2_filled_quaternion_vertical_correction_arcore_point_cloud_collection_complete.pickle','rb') as f: \n",
    "    arcore_point_cloud_collection = pickle.load(f)\n",
    "    \n",
    "arcore_spaces = [[],[],[],[],[],[],[]]\n",
    "    \n",
    "for [obj_num, name, timestamp], t_pointCloud, triangles in arcore_point_cloud_collection:\n",
    "    \n",
    "    unique_normals = np.unique(np.around(t_pointCloud[:,3:],decimals = 2),axis = 0)\n",
    "    \n",
    "    #print(obj_num, name, timestamp, len(unique_normals))\n",
    "    try:\n",
    "        arcore_spaces[int(obj_num)].append([\n",
    "            [obj_num, name, timestamp],\n",
    "            t_pointCloud, \n",
    "            triangles,\n",
    "            len(unique_normals)\n",
    "        ])\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "\n",
    "chosen_arcore_spaces = [[],[]]\n",
    "\n",
    "for space in arcore_spaces:\n",
    "    \n",
    "    chosen_arcore_spaces[0].append(space[0])\n",
    "    chosen_arcore_spaces[1].append(space[4])\n",
    "    \n",
    "len(arcore_spaces),len(chosen_arcore_spaces[0]),len(chosen_arcore_spaces[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.3.1: Generate the reference dataset for arcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Done with submap generation for object (0) reception in 5.687 seconds\n",
      "0 Done with submap generation for object (1) driveway in 8.982 seconds\n",
      "0 Done with submap generation for object (2) apartment in 9.716 seconds\n",
      "0 Done with submap generation for object (3) workstation in 10.189 seconds\n",
      "0 Done with submap generation for object (4) kitchen in 16.692 seconds\n",
      "0 Done with submap generation for object (5) hallway in 18.060 seconds\n",
      "0 Done with submap generation for object (6) stairwell in 29.315 seconds\n",
      "1 Done with submap generation for object (0) reception in 4.099 seconds\n",
      "1 Done with submap generation for object (1) driveway in 10.844 seconds\n",
      "1 Done with submap generation for object (2) apartment in 12.080 seconds\n",
      "1 Done with submap generation for object (3) workstation in 12.525 seconds\n",
      "1 Done with submap generation for object (4) kitchen in 22.851 seconds\n",
      "1 Done with submap generation for object (5) hallway in 24.233 seconds\n",
      "1 Done with submap generation for object (6) stairwell in 35.231 seconds\n"
     ]
    }
   ],
   "source": [
    "baseline_path = 'pointnetvlad_arcore_submaps_trash/'\n",
    "\n",
    "if not os.path.exists(baseline_path): os.mkdir(baseline_path)\n",
    "    \n",
    "for i in range(len(chosen_arcore_spaces)):\n",
    "    \n",
    "    raw_path = os.path.join(baseline_path,\"ref_dataset_\"+str(i))\n",
    "    raw_pc_path = os.path.join(raw_path,\"pointcloud_4m_0.25\")\n",
    "\n",
    "    if not os.path.exists(raw_path): os.mkdir(raw_path)\n",
    "    if not os.path.exists(raw_pc_path): os.mkdir(raw_pc_path)\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    csvfile = open(raw_path+\"/pointcloud_centroids_4m_0.25.csv\",'w',newline = '')\n",
    "\n",
    "    csv_writer = csv.writer(csvfile, delimiter = ',')\n",
    "    csv_writer.writerow(['timestamp', 'northing', 'easting','alting','obj'])\n",
    "\n",
    "    for obj_, [[obj_num, obj_name, timestamp] , pointCloud, triangles, num_normals] in enumerate(chosen_arcore_spaces[i]):\n",
    "\n",
    "        if obj_num == 0: #object_name == \"Reception-Data61-L5.obj\":\n",
    "            new_X = pointCloud[:,0] - np.mean(pointCloud[:,0]) + 50\n",
    "            new_Z = pointCloud[:,2] - np.mean(pointCloud[:,2]) + 0\n",
    "        elif obj_num == 1: #object_name == \"Driveway.obj\":\n",
    "            new_X = pointCloud[:,0] - np.mean(pointCloud[:,0]) - 25\n",
    "            new_Z = pointCloud[:,2] - np.mean(pointCloud[:,2]) - 50\n",
    "        elif obj_num == 2: #object_name == \"Apartment.obj\":\n",
    "            new_X = pointCloud[:,0] - np.mean(pointCloud[:,0]) + 25\n",
    "            new_Z = pointCloud[:,2] - np.mean(pointCloud[:,2]) - 50\n",
    "        elif obj_num == 3: #object_name == \"Workstations-Data61-L4.obj\":\n",
    "            new_X = pointCloud[:,0] - np.mean(pointCloud[:,0]) - 50\n",
    "            new_Z = pointCloud[:,2] - np.mean(pointCloud[:,2]) + 0\n",
    "        elif obj_num == 4: #object_name == \"Kitchen-Data61-L4.obj\":\n",
    "            new_X = pointCloud[:,0] - np.mean(pointCloud[:,0]) + 0\n",
    "            new_Z = pointCloud[:,2] - np.mean(pointCloud[:,2]) + 0\n",
    "        elif obj_num == 5: #object_name == \"HallWayToKitchen-Data61-L4.obj\":\n",
    "            new_X = pointCloud[:,0] - np.mean(pointCloud[:,0]) - 25\n",
    "            new_Z = pointCloud[:,2] - np.mean(pointCloud[:,2]) + 50\n",
    "        elif obj_num == 6: #object_name == \"StairWell-Data61-L4.obj\":\n",
    "            new_X = pointCloud[:,0] - np.mean(pointCloud[:,0]) + 25\n",
    "            new_Z = pointCloud[:,2] - np.mean(pointCloud[:,2]) + 50\n",
    "        else:\n",
    "            print(\"Error name at\",obj_, obj_num, obj_name)\n",
    "            continue\n",
    "\n",
    "        new_Y = pointCloud[:,1]\n",
    "\n",
    "        new_object_pointcloud = np.stack((new_X,new_Z,new_Y)).T\n",
    "\n",
    "        nbrs = NearestNeighbors(n_neighbors=min(20000,len(new_object_pointcloud)), algorithm='kd_tree').fit(new_object_pointcloud)\n",
    "\n",
    "        round_new_pointcloud = 0.25*100*np.around((0.01/0.25)*new_object_pointcloud,decimals=2)\n",
    "        unq_round_pointcloud = np.unique(round_new_pointcloud[:,:3],axis = 0)\n",
    "\n",
    "        raw_centroids = unq_round_pointcloud#+np.random.normal(0,0.25,unq_round_pointcloud.shape)\n",
    "\n",
    "        for northing, easting, alting in raw_centroids:\n",
    "\n",
    "            # Getting the points around our centroid defined by [northing, easting]\n",
    "            distances, indices = nbrs.kneighbors([[northing, easting, alting]])\n",
    "\n",
    "            #if max(distances[0]) < 0.5*spatial_span: continue\n",
    "\n",
    "            submap_pointcloud = new_object_pointcloud[indices[0,np.where(distances[0,:]<=spatial_span)[0]]]\n",
    "\n",
    "            if len(submap_pointcloud) == 0:\n",
    "                continue\n",
    "\n",
    "            # Centering and rescaling\n",
    "            submap_pointcloud = (submap_pointcloud - [northing, easting, alting])/spatial_span\n",
    "\n",
    "            if len(submap_pointcloud) > num_points:\n",
    "                submap_pointcloud = submap_pointcloud[np.random.choice(len(submap_pointcloud),num_points)]\n",
    "            elif len(submap_pointcloud) < num_points and len(submap_pointcloud) >= cutoff*num_points :\n",
    "                #print(i,submap_pointcloud.shape)\n",
    "                additional_pointcloud = submap_pointcloud[np.random.choice(len(submap_pointcloud),num_points-len(submap_pointcloud))]\n",
    "                additional_pointcloud = additional_pointcloud + np.random.normal(0,0.05,additional_pointcloud.shape)\n",
    "                submap_pointcloud = np.concatenate((submap_pointcloud,additional_pointcloud),axis = 0)\n",
    "            elif len(submap_pointcloud) < cutoff*num_points :\n",
    "                #continue\n",
    "                #print(i,submap_pointcloud.shape)\n",
    "                additional_pointcloud = submap_pointcloud[np.random.choice(len(submap_pointcloud),num_points-len(submap_pointcloud), True)]\n",
    "                additional_pointcloud = additional_pointcloud + np.random.normal(0,0.05,additional_pointcloud.shape)\n",
    "                submap_pointcloud = np.concatenate((submap_pointcloud,additional_pointcloud),axis = 0)\n",
    "\n",
    "            timestamp = int(10**16*(time.time()))\n",
    "\n",
    "            csv_writer.writerow([timestamp,northing,easting,alting,obj_])\n",
    "\n",
    "            with open(raw_pc_path+'/{}.pickle'.format(timestamp),'wb') as f:\n",
    "                pickle.dump(submap_pointcloud.T,f)\n",
    "\n",
    "        print(i,\"Done with submap generation for object ({}) {} in {:.3f} seconds\".format(obj_,obj_name,time.time()-t0))\n",
    "\n",
    "    csvfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done generating 1000 samples in 0.063 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([144., 121., 159., 154., 155., 138., 129.]),\n",
       " array([0, 1, 2, 3, 4, 5, 6, 7]),\n",
       " <a list of 7 Patch objects>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAeSUlEQVR4nO3deZhcVb3u8e8LYZDJgGkwZCCIiCKPCDcCTogiyiTxelXgokbFE1EPghOCw3G+6nGA6zlXMQoCiiCCCs4iMjkAJggyCiEEaBJJR6aACETf+8devSma6k6lu6uqO/1+nqeerr323mv9urq6frXW3ntt2SYiIgJgnW4HEBERY0eSQkRE1JIUIiKilqQQERG1JIWIiKglKURERC1JYQKRdKKkj45SXTMlPSBp3bJ8kaS3jUbdpb6fS5o7WvWtQbuflrRC0l9b3P7jkr7T7rg6RdKbJf2223FE9yQprCUkLZH0kKSVku6V9HtJR0iq/8a2j7D9qRbrevlQ29i+3fYmtv85CrE/4YPV9n62Tx1p3WsYxwzgfcCOtp/aZP1ekno7GVNEpyUprF1eZXtTYBvgc8AHgZNGuxFJk0a7zjFiG+Bvtpd3O5CIbklSWAvZvs/2ecDBwFxJOwFIOkXSp8vzKZJ+UnoVd0u6VNI6kr4NzAR+XIaHjpE0S5IlHS7pduA3DWWNCWI7SVdIuk/SuZK2KG094Rt2f29E0r7Ah4CDS3tXl/X1cFSJ6yOSbpO0XNJpkp5c1vXHMVfS7WXo58ODvTaSnlz27yv1faTU/3LgfGDrEscpA/bbGPh5w/oHJG1dVq9f6lwp6TpJsxv221rSOaW9WyW9e4jY9pd0fannTknvL+Wbl79Vn6R7yvPpDftdVIa9fl/i+rGkp0g6XdL9kv4oaVbD9pb0bkmLy+v1hcYe5YCYninp/PIe+Yuk1w8R/5tLnSvL73pYQ/nvJP1XeW/cKGnvhv3eIumGst9iSW8fUO8cSVeV3+WW8p7p/1ueJGlZeb0+rceGM58u6eLS3gpJ3xss7hjAdh5rwQNYAry8SfntwDvK81OAT5fnnwVOBNYrjxcDalYXMAswcBqwMfCkhrJJZZuLgDuBnco25wDfKev2AnoHixf4eP+2DesvAt5Wnr8VWAQ8DdgE+AHw7QGxfaPEtTPwMPCsQV6n04BzgU3LvjcBhw8W54B9m/0eHwf+AewPrFte18vKunWAhcB/AOuX+BcDrxyk/mXAi8vzzYFdy/OnAP8L2KjE/X3gRwNeq0XAdsCTgevL7/VyYFL5nb/VsL2BC4EtqL4A3NTwWr8Z+G15vjFwB/CWUs+uwArg2U1i3xi4H9ihLE/t367UuQp4D9V77WDgPmCLsv6AEruAlwB/b/jddyvb7lNez2nAM8u6HwFfL21vCVwBvL2sOwP4cNlnQ+BF3f4fHS+P9BTWfkup/vkHepTqH3cb24/avtTlv2kIH7f9oO2HBln/bdvX2n4Q+Cjw+v5vbiN0GPBl24ttPwAcBxwyoJfyCdsP2b4auJoqOTxOieVg4DjbK20vAb4EvHGE8f3W9s9cHV/5dkPbzwN6bH/S9iO2F1Mlr0MGqedRYEdJm9m+x/aVALb/Zvsc23+3vRL4DNWHZ6Nv2b7F9n1UPZpbbP/a9iqqJLLLgO0/b/tu27cDJwCHNonnQGCJ7W/ZXlXiOQd47SDx/wvYSdKTbC+zfV3DuuXACeW99j3gL1TJANs/LbHb9sXAr6i+pAAcDpxs+3zb/7J9p+0bJW0F7AccXd6Ty4HjG17bR6mGA7e2/Q/bOXjeoiSFtd804O4m5V+g+nb5q9JlP7aFuu5Yg/W3UX0rnNJSlEPbutTXWPckYKuGssazhf5O1aMYaArVN/aBdU0bYXwD296wJKxtqIab7u1/UA2VbdWsEqrewP7AbWXo4/kAkjaS9PUy3HU/cAkweUDCvavh+UNNlge+HgP/VlvzRNsAuw+I/zDgCQfhyxeBg4EjgGWSfirpmQ2b3DngS0fdpqT9JF1WhqjuLa9B//tmBnDLILGtV9rqj+3rVD0GgGOoeh5XlCG9tzapI5pIUliLSXoe1QfeE74llW/K77P9NOBVwHsbxnkH6zGsricxo+H5TKpvayuAB6mGPvrjWhfoWYN6l1J9CDTWvYrHf/C1YgWPfYNsrOvOFvdf0ymF7wButT254bGp7f2bVm7/0fYcqg+2HwFnlVXvA3YAdre9GbBnKdcaxtNo4N9q6SDxXzwg/k1sv2OQ+H9pex+qHuiNVL2iftMkNcY7E1gqaQOq3scXga1sTwZ+xmO/2x1UQ0vNYnsYmNIQ22a2n11i+avtf7O9NfB24KuSnj7UCxKVJIW1kKTNJB0InEk1Vn9Nk20OLAfjRDUW/M/ygOrD9mnDaPoNknaUtBHwSeDsMqRyE9W35wMkrQd8BNigYb+7gFmDHeykGh9+j6RtJW0C/B/ge2VopGUllrOAz0jaVNI2wHuBVq8zuAt4ispB7hZcAdwv6YOSniRpXUk7lWT9OJLWl3SYpCfbfpTH/iZQHUd4CLhX1cH7j7XY/lA+oOoA9gzgKKDZgdifAM+Q9EZJ65XH8yQ9q0n8W0k6SNUB+YeBBxrihyrRvbvU8TrgWVQf/utTvRf6gFWS9gNe0bDfScBbJO2t6oSAaZKeaXsZ1TDTl8r7fR1J20l6SYnndXrsYPw9VAl9xKdPTwRJCmuXH0taSfUt6sPAl6kOEjazPfBrqn/ePwBftX1RWfdZ4COlW/7+NWj/21QHs/9KdXDv3VCdDQW8E/gm1bfyB4HGs5G+X37+TdKVTeo9udR9CXAr1YHdI9cgrkZHlvYXU/WgvlvqXy3bN1IlqMXltWk25NK4/T+pemHPLXGvoHoNBksqbwSWlCGiI4A3lPITqA6irwAuA37RSryrcS7VQfCrgJ/S5NTlcvziFVTj9Eup/q6f5/EJvd86VD2apVTDlS+h+pv3u5zqPbeC6pjIa8uxkpVU75OzqD68/zdwXkMMV1C9h4+nOuB8MY/19N5ElVSuL/ueTdVLgep4zuWSHij1HWX71pZemQmu/2yTiJggJBnY3vaiDrX3Zqqzm17UifZiZNJTiIiIWpJCRETUMnwUERG19BQiIqI2ric2mzJlimfNmtXtMCIixpWFCxeusN3TbN24TgqzZs1iwYIF3Q4jImJckXTbYOsyfBQREbUkhYiIqCUpRERELUkhIiJqbUsKkk5WdZesaweUH6nqDk7XSfrPhvLjJC0q617ZrrgiImJw7Tz76BTgv6nu+gSApJcCc4Dn2H5Y0palfEeqSbeeTTXH+q8lPcOjcFP4iIhoXdt6CrYv4Yk3d3kH8DnbD5dt+m+QPgc40/bDZSbDRVS34YuIiA7q9DGFZwAvlnR5ubNU/7zy03j8naB6GeRuWJLmSVogaUFfX1+bw42ImFg6nRQmUd2QfA/gA8BZ5SYvze4g1XRSJtvzbc+2Pbunp+kFeRERMUydvqK5F/hBuVfrFZL+RXUv1l4ef3vA6TS/PWCMA7OO/Wm3Q1gjSz53QLdDiBgzOt1T+BHwMgBJz6C6a9IKqjsjHSJpA0nbUt2h6YoOxxYRMeG1racg6QxgL2CKpF6q+8qeDJxcTlN9BJhbeg3XSTqL6rZ6q4B35cyjiIjOa1tSsH3oIKve0KzQ9meo7t0aERFdkiuaIyKiNq6nzo6YaHIQP9otSSEmvPH2QRvRThk+ioiIWpJCRETUkhQiIqKWpBAREbUkhYiIqCUpRERELUkhIiJqSQoREVFLUoiIiFqSQkRE1JIUIiKilqQQERG1CTsh3nibBC2zTUZEJ6SnEBERtbYlBUknS1pebr05cN37JVnSlLIsSV+RtEjSnyXt2q64IiJicO3sKZwC7DuwUNIMYB/g9obi/YDty2Me8LU2xhUREYNoW1KwfQlwd5NVxwPHAG4omwOc5splwGRJU9sVW0RENNfRYwqSDgLutH31gFXTgDsalntLWbM65klaIGlBX19fmyKNiJiYOpYUJG0EfBj4j2arm5S5SRm259uebXt2T0/PaIYYETHhdfKU1O2AbYGrJQFMB66UtBtVz2BGw7bTgaUdjC0iIuhgUrB9DbBl/7KkJcBs2ysknQf8u6Qzgd2B+2wv61RsEdEe4+l6oFwLVGnnKalnAH8AdpDUK+nwITb/GbAYWAR8A3hnu+KKiIjBta2nYPvQ1ayf1fDcwLvaFUtERLQmVzRHREQtSSEiImpJChERUUtSiIiIWpJCRETUkhQiIqKWpBAREbUkhYiIqCUpREREbcLeozkiotF4mqcJ2jdXU3oKERFRS1KIiIhakkJERNSSFCIiopakEBERtSSFiIioJSlEREStnbfjPFnScknXNpR9QdKNkv4s6YeSJjesO07SIkl/kfTKdsUVERGDa2dP4RRg3wFl5wM72X4OcBNwHICkHYFDgGeXfb4qad02xhYREU208x7Nl0iaNaDsVw2LlwGvLc/nAGfafhi4VdIiYDfgD+2Kb7wZb1dbRsT41M1jCm8Ffl6eTwPuaFjXW8oiIqKDupIUJH0YWAWc3l/UZDMPsu88SQskLejr62tXiBERE1LHk4KkucCBwGG2+z/4e4EZDZtNB5Y229/2fNuzbc/u6elpb7ARERNMR5OCpH2BDwIH2f57w6rzgEMkbSBpW2B74IpOxhYREW080CzpDGAvYIqkXuBjVGcbbQCcLwngMttH2L5O0lnA9VTDSu+y/c92xRYREc218+yjQ5sUnzTE9p8BPtOueCIiYvVyRXNERNSSFCIiopakEBERtSSFiIioJSlEREQtSSEiImpJChERUUtSiIiIWpJCRETUWk4KkjZuZyAREdF9q00Kkl4g6XrghrK8s6Svtj2yiIjouFZ6CscDrwT+BmD7amDPdgYVERHd0dLwke07BhRlBtOIiLVQK7Ok3iHpBYAlrQ+8mzKUFBERa5dWegpHAO+iumdyL/DcshwREWuZ1fYUbK8ADutALBER0WWtnH10qqTJDcubSzq5vWFFREQ3tDJ89Bzb9/Yv2L4H2GV1O0k6WdJySdc2lG0h6XxJN5efm5dySfqKpEWS/ixp1+H8MhERMTKtJIV1+j+8ofpgp7UD1KcA+w4oOxa4wPb2wAVlGWA/YPvymAd8rYX6IyJilLXy4f4l4PeSzi7Lr6OFeynbvkTSrAHFc4C9yvNTgYuAD5by02wbuEzSZElTbS9rIb6IiBglrRxoPk3SQuClgIDX2L5+mO1t1f9Bb3uZpC1L+TSg8VqI3lKWpBAR0UGt9BSwfZ2kPmBDAEkzbd8+inGoWbNNN5TmUQ0xMXPmzFEMISIiWjn76CBJNwO3AhcDS4CfD7O9uyRNLfVOBZaX8l5gRsN204GlzSqwPd/2bNuze3p6hhlGREQ008qB5k8BewA32d4W2Bv43TDbOw+YW57PBc5tKH9TOQtpD+C+HE+IiOi8VpLCo7b/RnUW0jq2L6S6qnlIks4A/gDsIKlX0uHA54B9Ss9jn7IM8DNgMbAI+AbwzjX/VSIiYqRaOaZwr6RNgEuB0yUtB1atbifbhw6yau8m25pMnRER0XWt9BTmAA8BRwO/AG4BXtXOoCIiojtaOSX1QUlPBXYD7gZ+WYaTIiJiLdPK2UdvA64AXgO8lurisre2O7CIiOi8Vo4pfADYpb93IOkpwO+BTIoXEbGWaeWYQi+wsmF5JY+/+jgiItYSrfQU7gQul3Qu1VXGc4ArJL0XwPaX2xhfRER0UCtJ4Zby6Nd/wdmmox9ORER0UytnH32i/7mkdYBNbN/f1qgiIqIrWjn76LuSNpO0MXA98BdJH2h/aBER0WmtHGjesfQMXk01HcVM4I1tjSoiIrqilaSwnqT1qJLCubYfZZBprSMiYnxrJSl8nWq67I2BSyRtA+SYQkTEWmi1ScH2V2xPs71/mbjudqq7sEVExFqmpTuvNSqJYbWzpEZExPjTyvBRRERMEEkKERFRa+U6hY0kfVTSN8ry9pIObH9oERHRaa30FL4FPAw8vyz3Ap8eSaOS3iPpOknXSjpD0oaStpV0uaSbJX1P0vojaSMiItZcK0lhO9v/CTwKYPshQMNtUNI04N3AbNs7AesChwCfB463vT1wD3D4cNuIiIjhaSUpPCLpSZQL1iRtR9VzGIlJwJMkTQI2ApYBLwPOLutPpbpYLiIiOqiVpPAxqnszz5B0OnABcMxwG7R9J/BFqusdlgH3AQuBe233n+raC0wbbhsRETE8rcySer6kK4E9qIaNjrK9YrgNStqc6p4M2wL3At8H9mvW9CD7zwPmAcycOXO4YURERBODJgVJuw4oWlZ+zpQ00/aVw2zz5cCttvtKOz8AXgBMljSp9BamA0ub7Wx7PjAfYPbs2ZmDKSJiFA3VU/jSEOtMdQxgOG4H9pC0EfAQsDewALgQeC1wJjCXx27mExERHTJoUrDdlvmNbF8u6WzgSqrpMv5E9c3/p8CZkj5dyk5qR/sRETG41R5TkLQh8E7gRVQ9hEuBE23/Y7iN2v4Y1QHsRouB3YZbZ0REjFwrE+KdBqwE/qssHwp8G3hdu4KKiIjuaCUp7GB754blCyVd3a6AIiKie1q5TuFPkvboX5C0O/C79oUUERHd0kpPYXfgTZJuL8szgRskXUN1e4XntC26iIjoqFaSwr5tjyIiIsaEVq5ovq1chTyjcfsRXLwWERFjVCunpH4KeDNwC49NPTGSi9ciImKMamX46PVU02c/0u5gIiKiu1o5++haYHK7A4mIiO5rpafwWarTUq+l4T4Ktg9qW1QREdEVrSSFU6nuinYN8K/2hhMREd3USlJYYfsrbY8kIiK6rpWksFDSZ4HzePzwUU5JjYhYy7SSFHYpP/doKMspqRERa6FWLl5ry30VIiJi7Gmlp4CkA4BnAxv2l9n+ZLuCioiI7ljtdQqSTgQOBo4ERHUfhW3aHFdERHRBKxevvcD2m4B7bH8CeD7VPEjDJmmypLMl3SjpBknPl7SFpPMl3Vx+bj6SNiIiYs21khQeKj//Lmlr4FFg2xG2+3+BX9h+JrAzcANwLHCB7e2BC8pyRER0UCtJ4SeSJgNfAK4ElgBnDLdBSZsBewInAdh+xPa9wByqC+UoP1893DYiImJ4Wjn76FPl6TmSfgJsaPu+EbT5NKAP+JaknYGFwFHAVraXlTaXSdpyBG1ERMQwDNpTkPQ8SU9tWH4TcBbwKUlbjKDNScCuwNds7wI8yBoMFUmaJ2mBpAV9fX0jCCMiIgYaavjo68AjAJL2BD4HnAbcB8wfQZu9QK/ty8vy2VRJ4i5JU0t7U4HlzXa2Pd/2bNuze3p6RhBGREQMNFRSWNf23eX5wcB82+fY/ijw9OE2aPuvwB2SdihFewPXU02jMbeUzQXOHW4bERExPEMdU1hX0iTbq6g+uOe1uF8rjgROl7Q+sBh4C1WCOkvS4cDtVNdDREREBw314X4GcLGkFVSnpV4KIOnpVENIw2b7KmB2k1V7j6TeiIgYmUGTgu3PSLoAmAr8ynb//ZnXofqmHxERa5khh4FsX9ak7Kb2hRMREd3UysVrERExQSQpRERELUkhIiJqSQoREVFLUoiIiFqSQkRE1JIUIiKilqQQERG1JIWIiKglKURERC1JISIiakkKERFRS1KIiIhakkJERNSSFCIiopakEBERta4lBUnrSvqTpJ+U5W0lXS7pZknfK/dvjoiIDupmT+Eo4IaG5c8Dx9veHrgHOLwrUUVETGBdSQqSpgMHAN8sywJeBpxdNjkVeHU3YouImMi61VM4ATgG+FdZfgpwr+1VZbkXmNZsR0nzJC2QtKCvr6/9kUZETCAdTwqSDgSW217YWNxkUzfb3/Z827Ntz+7p6WlLjBERE9WkLrT5QuAgSfsDGwKbUfUcJkuaVHoL04GlXYgtImJC63hPwfZxtqfbngUcAvzG9mHAhcBry2ZzgXM7HVtExEQ3lq5T+CDwXkmLqI4xnNTleCIiJpxuDB/VbF8EXFSeLwZ262Y8ERET3VjqKURERJclKURERC1JISIiakkKERFRS1KIiIhakkJERNSSFCIiopakEBERtSSFiIioJSlEREQtSSEiImpJChERUUtSiIiIWpJCRETUkhQiIqKWpBAREbUkhYiIqHU8KUiaIelCSTdIuk7SUaV8C0nnS7q5/Ny807FFREx03egprALeZ/tZwB7AuyTtCBwLXGB7e+CCshwRER3U8aRge5ntK8vzlcANwDRgDnBq2exU4NWdji0iYqLr6jEFSbOAXYDLga1sL4MqcQBbDrLPPEkLJC3o6+vrVKgRERNC15KCpE2Ac4Cjbd/f6n6259uebXt2T09P+wKMiJiAupIUJK1HlRBOt/2DUnyXpKll/VRgeTdii4iYyLpx9pGAk4AbbH+5YdV5wNzyfC5wbqdji4iY6CZ1oc0XAm8ErpF0VSn7EPA54CxJhwO3A6/rQmwRERNax5OC7d8CGmT13p2MJSIiHi9XNEdERC1JISIiakkKERFRS1KIiIhakkJERNSSFCIiopakEBERtSSFiIioJSlEREQtSSEiImpJChERUUtSiIiIWpJCRETUkhQiIqKWpBAREbUkhYiIqCUpREREbcwlBUn7SvqLpEWSju12PBERE8mYSgqS1gX+H7AfsCNwqKQduxtVRMTEMaaSArAbsMj2YtuPAGcCc7ocU0TEhDGp2wEMMA24o2G5F9i9cQNJ84B5ZfEBSX8ZZltTgBXD3LcbxlO84ylWGF/xjqdYYXzFO55iRZ8fUbzbDLZirCUFNSnz4xbs+cD8ETckLbA9e6T1dMp4inc8xQrjK97xFCuMr3jHU6zQvnjH2vBRLzCjYXk6sLRLsURETDhjLSn8Edhe0raS1gcOAc7rckwRERPGmBo+sr1K0r8DvwTWBU62fV2bmhvxEFSHjad4x1OsML7iHU+xwviKdzzFCm2KV7ZXv1VEREwIY234KCIiuihJISIiahMyKYynqTQknSxpuaRrux3L6kiaIelCSTdIuk7SUd2OaTCSNpR0haSrS6yf6HZMrZC0rqQ/SfpJt2MZiqQlkq6RdJWkBd2OZ3UkTZZ0tqQby/v3+d2OqRlJO5TXtP9xv6SjR7WNiXZMoUylcROwD9UpsH8EDrV9fVcDG4SkPYEHgNNs79TteIYiaSow1faVkjYFFgKvHouvrSQBG9t+QNJ6wG+Bo2xf1uXQhiTpvcBsYDPbB3Y7nsFIWgLMtj0uLgaTdCpwqe1vljMfN7J9b7fjGkr5LLsT2N32baNV70TsKYyrqTRsXwLc3e04WmF7me0ry/OVwA1UV6mPOa48UBbXK48x/Q1J0nTgAOCb3Y5lbSJpM2BP4CQA24+M9YRQ7A3cMpoJASZmUmg2lcaY/OAazyTNAnYBLu9uJIMrQzFXAcuB822P2ViLE4BjgH91O5AWGPiVpIVlapqx7GlAH/CtMjT3TUkbdzuoFhwCnDHalU7EpLDaqTRiZCRtApwDHG37/m7HMxjb/7T9XKor53eTNGaH5yQdCCy3vbDbsbTohbZ3pZrx+F1lGHSsmgTsCnzN9i7Ag8BYP9a4PnAQ8P3RrnsiJoVMpdFGZXz+HOB02z/odjytKEMFFwH7djmUobwQOKiM1Z8JvEzSd7ob0uBsLy0/lwM/pBq2Hat6gd6GnuLZVEliLNsPuNL2XaNd8URMCplKo03KwduTgBtsf7nb8QxFUo+kyeX5k4CXAzd2N6rB2T7O9nTbs6jes7+x/YYuh9WUpI3LiQaUYZhXAGP27DnbfwXukLRDKdobGHMnRwxwKG0YOoIxNs1FJ3R4Ko0Rk3QGsBcwRVIv8DHbJ3U3qkG9EHgjcE0Zqwf4kO2fdTGmwUwFTi1ncKwDnGV7TJ/mOY5sBfyw+o7AJOC7tn/R3ZBW60jg9PJFcTHwli7HMyhJG1GdPfn2ttQ/0U5JjYiIwU3E4aOIiBhEkkJERNSSFCIiopakEBERtSSFiIioJSlErIakp0o6U9Itkq6X9DNJzxjF+veS9ILRqi9iJJIUIoZQLsj7IXCR7e1s7wh8iOpc/NGyF5CkEGNCkkLE0F4KPGr7xP4C21cBv5X0BUnXlvsGHAz1t/76IjhJ/y3pzeX5EkmfkHRl2eeZZeLAI4D3lPnxX9zB3y3iCSbcFc0Ra2gnqvtCDPQa4LnAzsAU4I+SLmmhvhW2d5X0TuD9tt8m6UTgAdtfHLWoI4YpPYWI4XkRcEaZafUu4GLgeS3s1z9J4EJgVptiixi2JIWIoV0H/I8m5c2mYAdYxeP/rzYcsP7h8vOfpKceY1CSQsTQfgNsIOnf+gskPQ+4Bzi43Kinh+rOXVcAtwE7StpA0pOpZtxcnZXApqMfesSayzeViCHYtqT/CZwg6VjgH8AS4GhgE+Bqqps0HVOmYEbSWcCfgZuBP7XQzI+BsyXNAY60femo/yIRLcosqRERUcvwUURE1JIUIiKilqQQERG1JIWIiKglKURERC1JISIiakkKERFR+//YRuVt9ajE/AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples = 1000\n",
    "\n",
    "sample_arcore_points = []\n",
    "\n",
    "samples_indeces = []\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "for i in np.arange(samples):\n",
    "\n",
    "    random_space = np.random.randint(len(arcore_spaces))\n",
    "    random_sample = np.random.randint(len(arcore_spaces[random_space]))\n",
    "\n",
    "    object_name = arcore_spaces[random_space][random_sample][0][1]\n",
    "    pointCloud = arcore_spaces[random_space][random_sample][1]\n",
    "    triangles = arcore_spaces[random_space][random_sample][2]\n",
    "    \n",
    "    triangle_index = np.random.choice(np.arange(len(triangles)))\n",
    "    vertex_index = triangles[triangle_index,1]\n",
    "    original_vertex = pointCloud[vertex_index]\n",
    "\n",
    "    sample_arcore_points.append([\n",
    "        random_space,\n",
    "        random_sample, \n",
    "        object_name, \n",
    "        original_vertex\n",
    "    ])\n",
    "    \n",
    "    samples_indeces.append(random_space)\n",
    "    \n",
    "print(\"Done generating\",len(sample_arcore_points),\"samples in {:.3f} seconds.\".format(time.time()-t0))\n",
    "\n",
    "with open('sample_arcore_points.pickle','wb') as f:\n",
    "    pickle.dump(sample_arcore_points,f)\n",
    "    \n",
    "plt.title(\"Distribution of the sample spaces\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Sample space\")\n",
    "plt.hist(samples_indeces,bins = np.arange(0,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.3.3: Generate the test submaps:\n",
    " - using Raw spaces for validation\n",
    " - using Ransac spaces for evaluation\n",
    " - using Ransac spaces for the successive case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  pointnetvlad_arcore_submaps/partial_radius_3.0/pointcloud_4m\n",
      "   Done with submap generation for radius 3.0 ( 1000 samples) in 16.151 seconds\n",
      "  pointnetvlad_arcore_submaps/partial_radius_3.25/pointcloud_4m\n",
      "   Done with submap generation for radius 3.25 ( 6270 samples) in 34.263 seconds\n",
      "  pointnetvlad_arcore_submaps/partial_radius_3.5/pointcloud_4m\n",
      "   Done with submap generation for radius 3.5 ( 7501 samples) in 41.841 seconds\n",
      "  pointnetvlad_arcore_submaps/partial_radius_3.75/pointcloud_4m\n",
      "   Done with submap generation for radius 3.75 ( 8648 samples) in 45.844 seconds\n",
      "  pointnetvlad_arcore_submaps/partial_radius_4.0/pointcloud_4m\n",
      "   Done with submap generation for radius 4.0 ( 9607 samples) in 49.289 seconds\n",
      "  pointnetvlad_arcore_submaps/partial_radius_4.25/pointcloud_4m\n",
      "   Done with submap generation for radius 4.25 ( 10671 samples) in 51.836 seconds\n",
      "  pointnetvlad_arcore_submaps/partial_radius_4.5/pointcloud_4m\n",
      "   Done with submap generation for radius 4.5 ( 11581 samples) in 61.691 seconds\n",
      "  pointnetvlad_arcore_submaps/partial_radius_4.75/pointcloud_4m\n",
      "   Done with submap generation for radius 4.75 ( 12437 samples) in 63.022 seconds\n",
      "  pointnetvlad_arcore_submaps/partial_radius_5.0/pointcloud_4m\n",
      "   Done with submap generation for radius 5.0 ( 13202 samples) in 66.408 seconds\n"
     ]
    }
   ],
   "source": [
    "# One-time releases Raw partial spaces\n",
    "\n",
    "baseline_path = 'pointnetvlad_arcore_submaps/'\n",
    "\n",
    "if not os.path.exists(baseline_path): os.mkdir(baseline_path)\n",
    "\n",
    "for radius in np.arange(3.0,5.1,0.25):\n",
    "    \n",
    "    per_radius_partial_length = []\n",
    "    \n",
    "    t1 = time.time()\n",
    "            \n",
    "    partial_path = os.path.join(baseline_path,\"partial_radius_\"+str(radius))\n",
    "    pointcloud_partial_path = os.path.join(partial_path,\"pointcloud_4m\")\n",
    "    #pointcloud_partial_bin_path = os.path.join(partial_path,\"pointcloud_4m_npy\")\n",
    "\n",
    "    if not os.path.exists(partial_path): os.mkdir(partial_path)\n",
    "    if not os.path.exists(pointcloud_partial_path): os.mkdir(pointcloud_partial_path)\n",
    "    #if not os.path.exists(pointcloud_partial_bin_path): os.mkdir(pointcloud_partial_bin_path)\n",
    "\n",
    "    print(\" \",pointcloud_partial_path)\n",
    "    #\"\"\"\n",
    "    csvfile = open(partial_path+\"/pointcloud_centroids_4m.csv\",'w',newline = '')\n",
    "\n",
    "    csv_writer = csv.writer(csvfile, delimiter = ',')\n",
    "    csv_writer.writerow(['timestamp', 'northing', 'easting', 'alting','obj'])\n",
    "    #\"\"\"\n",
    "    count = 0\n",
    "    \n",
    "    for obj_, obj_sample, object_name, original_vertex in sample_arcore_points:\n",
    "        \n",
    "        new_partial_pointcloud = []\n",
    "        new_vX = []\n",
    "        new_vZ = []\n",
    "        \n",
    "        try:\n",
    "            object_, ransac_pointCloud, tri_, u_n_ = arcore_spaces[obj_][obj_sample]\n",
    "            \n",
    "            ransac_nbrs = NearestNeighbors(n_neighbors=min(20000,len(ransac_pointCloud)), algorithm='kd_tree').fit(ransac_pointCloud[:,:3])\n",
    "            \n",
    "            dist_, ind_ = ransac_nbrs.kneighbors([original_vertex[:3]])\n",
    "            pointCloud =  ransac_pointCloud[ind_[0,np.where(dist_[0,:]<=radius)[0]]]\n",
    "            \n",
    "        except:\n",
    "            print(\"Can't get pointcloud for\",obj_, sample, object_name, original_vertex)\n",
    "            continue\n",
    "            \n",
    "        #if len(gen_planes) == 0: continue\n",
    "        if len(pointCloud) == 0: continue\n",
    "\n",
    "        if obj_ == 0: #object_name == \"Reception-Data61-L5.obj\":\n",
    "            new_X = pointCloud[:,0] + 50\n",
    "            new_Z = pointCloud[:,2] + 0\n",
    "            new_vX = original_vertex[0] + 50\n",
    "            new_vZ = original_vertex[2] + 0\n",
    "        elif obj_ == 1: #object_name == \"Driveway.obj\":\n",
    "            new_X = pointCloud[:,0] - 25\n",
    "            new_Z = pointCloud[:,2] - 50\n",
    "            new_vX = original_vertex[0] - 25\n",
    "            new_vZ = original_vertex[2] - 50\n",
    "        elif obj_ == 2: #object_name == \"Apartment.obj\":\n",
    "            new_X = pointCloud[:,0] + 25\n",
    "            new_Z = pointCloud[:,2] - 50\n",
    "            new_vX = original_vertex[0] + 25\n",
    "            new_vZ = original_vertex[2] - 50\n",
    "        elif obj_ == 3: #object_name == \"Workstations-Data61-L4.obj\":\n",
    "            new_X = pointCloud[:,0] - 50\n",
    "            new_Z = pointCloud[:,2] + 0\n",
    "            new_vX = original_vertex[0] - 50\n",
    "            new_vZ = original_vertex[2] + 0\n",
    "        elif obj_ == 4: #object_name == \"Kitchen-Data61-L4.obj\":\n",
    "            new_X = pointCloud[:,0] + 0\n",
    "            new_Z = pointCloud[:,2] + 0\n",
    "            new_vX = original_vertex[0] + 0\n",
    "            new_vZ = original_vertex[2] + 0\n",
    "        elif obj_ == 5: #object_name == \"HallWayToKitchen-Data61-L4.obj\":\n",
    "            new_X = pointCloud[:,0] - 25\n",
    "            new_Z = pointCloud[:,2] + 50\n",
    "            new_vX = original_vertex[0] - 25\n",
    "            new_vZ = original_vertex[2] + 50\n",
    "        elif obj_ == 6: #object_name == \"StairWell-Data61-L4.obj\":\n",
    "            new_X = pointCloud[:,0] + 25\n",
    "            new_Z = pointCloud[:,2] + 50\n",
    "            new_vX = original_vertex[0] + 25\n",
    "            new_vZ = original_vertex[2] + 50\n",
    "        else:\n",
    "            print(\"Error:\",obj_meta)\n",
    "\n",
    "        new_Y = pointCloud[:,1]\n",
    "\n",
    "        new_partial_pointcloud = np.stack((new_X,new_Z,new_Y)).T\n",
    "        \n",
    "        max_known_span = max(np.amax(new_partial_pointcloud, axis = 0) - np.amin(new_partial_pointcloud, axis = 0))\n",
    "        \n",
    "        nbrs = NearestNeighbors(n_neighbors=min(2*num_points,len(new_partial_pointcloud)), algorithm='kd_tree').fit(new_partial_pointcloud)\n",
    "\n",
    "        # Get submap \"centroids\" by quantizing by 0.25m, i.e. round then unique\n",
    "        if max_known_span > 3*spatial_span:\n",
    "            round_new_partial_pointcloud = 100*np.around(0.01*new_partial_pointcloud,decimals=2)\n",
    "            unq_round_partial_pointcloud = np.unique(round_new_partial_pointcloud[:,:3],axis = 0)\n",
    "        #    \n",
    "            raw_partial_centroids = unq_round_partial_pointcloud\n",
    "            c_nbrs = NearestNeighbors(n_neighbors = min(25,len(raw_partial_centroids)),  algorithm='kd_tree').fit(raw_partial_centroids)\n",
    "            c_dist, c_ind = c_nbrs.kneighbors(raw_partial_centroids)\n",
    "\n",
    "            ia1, ia2 = np.where(c_dist < 1.73)\n",
    "            \n",
    "\n",
    "            dist_bins = np.bincount(ia1)\n",
    "            max_dist = max(np.bincount(ia1))\n",
    "            raw_partial_centroids = raw_partial_centroids[[i for i, j in enumerate(dist_bins) if j == max_dist]]\n",
    "            \n",
    "            raw_partial_centroids = raw_partial_centroids+np.random.normal(0,interval,raw_partial_centroids.shape)\n",
    "            \n",
    "        else:\n",
    "            # Correcting this, because the attacker is supposed to not know the true centroid\n",
    "            # and has to estimate it instead.\n",
    "            #raw_partial_centroids = [[new_vX, new_vZ, original_vertex[1]]]        \n",
    "\n",
    "            raw_partial_centroids = [np.mean(new_partial_pointcloud, axis = 0)]\n",
    "            \n",
    "        for northing, easting, alting in raw_partial_centroids:\n",
    "            \n",
    "            # Getting the points around our centroid defined by [northing, easting]\n",
    "            distances, indices = nbrs.kneighbors([[northing, easting, alting]])\n",
    "            \n",
    "            #if max(distances[0]) < 0.5*spatial_span: continue\n",
    "                \n",
    "            submap_pointcloud = new_partial_pointcloud[indices[0,np.where(distances[0,:]<=spatial_span)[0]]]\n",
    "\n",
    "            if len(submap_pointcloud) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Centering and rescaling\n",
    "            submap_pointcloud = (submap_pointcloud - [northing, easting, alting])/spatial_span\n",
    "\n",
    "            if len(submap_pointcloud) > num_points:\n",
    "                submap_pointcloud = submap_pointcloud[np.random.choice(len(submap_pointcloud),num_points)]\n",
    "            elif len(submap_pointcloud) < num_points and len(submap_pointcloud) >= cutoff*num_points :\n",
    "                #print(i,submap_pointcloud.shape)\n",
    "                additional_pointcloud = submap_pointcloud[np.random.choice(len(submap_pointcloud),num_points-len(submap_pointcloud))]\n",
    "                additional_pointcloud = additional_pointcloud + np.random.normal(0,0.05,additional_pointcloud.shape)\n",
    "                submap_pointcloud = np.concatenate((submap_pointcloud,additional_pointcloud),axis = 0)\n",
    "            elif len(submap_pointcloud) < cutoff*num_points :\n",
    "                #continue\n",
    "                #print(i,submap_pointcloud.shape)\n",
    "                additional_pointcloud = submap_pointcloud[np.random.choice(len(submap_pointcloud),num_points-len(submap_pointcloud), True)]\n",
    "                additional_pointcloud = additional_pointcloud + np.random.normal(0,0.05,additional_pointcloud.shape)\n",
    "                submap_pointcloud = np.concatenate((submap_pointcloud,additional_pointcloud),axis = 0)\n",
    "\n",
    "            timestamp = int(10**16*(time.time()))\n",
    "            \n",
    "            csv_writer.writerow([timestamp,northing,easting,alting,obj_])\n",
    "            \n",
    "            with open(pointcloud_partial_path+'/{}.pickle'.format(timestamp),'wb') as f:\n",
    "                pickle.dump(submap_pointcloud.T,f)\n",
    "\n",
    "            count += 1\n",
    "\n",
    "\n",
    "    print(\"   Done with submap generation for radius {} ( {} samples) in {:.3f} seconds\".format(radius,count,time.time()-t1))\n",
    "    csvfile.close()\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0.3.4: Building database and query files for evaluation with pointnetVLAD \n",
    " - the combined Raw and RANSAC referece database \n",
    " - for validation with one-time released Raw spaces\n",
    " - for testing with one-time released RANSAC spaces\n",
    " - for testing with successive RANSAC spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_dataset_0\n",
      "ref_dataset_1\n",
      "Done getting database trees.\n",
      "Database (Tree) sets: 2\n",
      "Done  pointnetvlad_arcore_submaps/3d_evaluation_database.pickle\n"
     ]
    }
   ],
   "source": [
    "base_path= \"pointnetvlad_arcore_submaps/\"#\"../partial_dataset/\"\n",
    "\n",
    "construct_query_and_database_sets(\n",
    "    base_path, \n",
    "    ['ref_dataset_0','ref_dataset_1'], \n",
    "    \"/pointcloud_4m_0.25/\",\n",
    "    \"pointcloud_centroids_4m_0.25.csv\",\n",
    "    True\n",
    ")#, all_folders[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partial_radius_3.0\n",
      " Test (Tree) sets: 1\n",
      "Done  pointnetvlad_arcore_submaps/3d_partial_radius_3.0_evaluation_query.pickle\n",
      "partial_radius_3.5\n",
      " Test (Tree) sets: 1\n",
      "Done  pointnetvlad_arcore_submaps/3d_partial_radius_3.5_evaluation_query.pickle\n",
      "partial_radius_4.0\n",
      " Test (Tree) sets: 1\n",
      "Done  pointnetvlad_arcore_submaps/3d_partial_radius_4.0_evaluation_query.pickle\n",
      "partial_radius_4.5\n",
      " Test (Tree) sets: 1\n",
      "Done  pointnetvlad_arcore_submaps/3d_partial_radius_4.5_evaluation_query.pickle\n",
      "partial_radius_5.0\n",
      " Test (Tree) sets: 1\n",
      "Done  pointnetvlad_arcore_submaps/3d_partial_radius_5.0_evaluation_query.pickle\n"
     ]
    }
   ],
   "source": [
    "# For the Ransac queries.\n",
    "\n",
    "for radius in np.arange(3.0,5.1,0.5):\n",
    "    \n",
    "    partial_path = 'partial_radius_'+str(radius)\n",
    "    \n",
    "    print(partial_path)\n",
    "    construct_query_sets(\n",
    "        base_path,\n",
    "        partial_path, \n",
    "        \"/pointcloud_4m/\", \n",
    "        \"pointcloud_centroids_4m.csv\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-3d_env] *",
   "language": "python",
   "name": "conda-env-.conda-3d_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
